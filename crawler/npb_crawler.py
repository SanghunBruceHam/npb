#!/Users/sanghunbruceham/Documents/GitHub/npb/crawler/venv/bin/python3

"""
NPB Enhanced Database Crawler
ë‹ˆì¹¸ìŠ¤í¬ì¸  ë°ì´í„° + PostgreSQL DB í†µí•© í¬ë¡¤ëŸ¬

ê¸°ëŠ¥:
- ê²½ê¸° ê¸°ë³¸ ì •ë³´ + ì„¸ë¶€ ì •ë³´ í¬ë¡¤ë§
- ì´ë‹ë³„ ë“ì  JSONB ì €ì¥
- ì—°ì¥ì „, ë¬´ìŠ¹ë¶€, ì·¨ì†Œ ê²½ê¸° ì²˜ë¦¬
- ì‹¤ì‹œê°„ ìˆœìœ„ ê³„ì‚° ë° ì—…ë°ì´íŠ¸
- í¬ë¡¤ë§ ë¡œê·¸ ë° ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'venv', 'lib', 'python3.13', 'site-packages'))

import requests
from bs4 import BeautifulSoup
import re
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass, asdict
import psycopg2
from psycopg2.extras import RealDictCursor, Json
from dotenv import load_dotenv
import pytz

# ë¡œì»¬ ëª¨ë“ˆ import
from config import NPB_TEAMS, DATA_SOURCES, CRAWLER_CONFIG
from utils import clean_text, get_jst_now, normalize_team_name, validate_game_data

load_dotenv()

@dataclass  
class EnhancedGameResult:
    """í–¥ìƒëœ ê²½ê¸° ê²°ê³¼ ë°ì´í„°"""
    # ê¸°ë³¸ ì •ë³´
    game_date: str
    home_team: str
    away_team: str 
    home_score: int
    away_score: int
    
    # ì„¸ë¶€ ì •ë³´
    game_status: str = "completed"
    is_extra_innings: bool = False
    total_innings: int = 9
    is_draw: bool = False
    is_cancelled: bool = False
    stadium: str = ""
    game_start_time: str = ""
    
    # ì´ë‹ë³„ ë“ì  (JSONBë¡œ ì €ì¥)
    home_inning_scores: List[int] = None
    away_inning_scores: List[int] = None
    
    def to_db_dict(self) -> Dict:
        """DB ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬ ë³€í™˜"""
        return {
            'game_date': self.game_date,
            'home_score': self.home_score,
            'away_score': self.away_score,
            'game_status': self.game_status,
            'is_extra_innings': self.is_extra_innings,
            'total_innings': self.total_innings,
            'is_draw': self.is_draw,
            'is_cancelled': self.is_cancelled,
            'stadium': self.stadium,
            'game_start_time': self.game_start_time if self.game_start_time else None,
            'home_inning_scores': Json(self.home_inning_scores) if self.home_inning_scores else None,
            'away_inning_scores': Json(self.away_inning_scores) if self.away_inning_scores else None
        }

class NPBCrawler:
    """NPB í–¥ìƒëœ ë°ì´í„°ë² ì´ìŠ¤ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.setup_config()
        self.setup_database()
        self.setup_session()
        self.setup_team_mapping()
        self.setup_file_logging()
        
    def setup_config(self):
        """ê¸°ë³¸ ì„¤ì •"""
        self.base_url = DATA_SOURCES['nikkansports']['score_pattern']
        self.jst = pytz.timezone('Asia/Tokyo')
        self.season_year = CRAWLER_CONFIG['validation']['current_season_year']
        
    def setup_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •"""
        self.db_config = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'port': os.getenv('DB_PORT', '5432'),
            'database': os.getenv('DB_NAME', 'npb_dashboard'),
            'user': os.getenv('DB_USER', 'sanghunbruceham'),
            'password': os.getenv('DB_PASSWORD', '')
        }
        
    def setup_session(self):
        """HTTP ì„¸ì…˜ ì„¤ì •"""
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': CRAWLER_CONFIG['user_agent'],
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ja,en;q=0.5',
            'Referer': DATA_SOURCES['nikkansports']['base_url']
        })
        
    def setup_team_mapping(self):
        """íŒ€ ë§¤í•‘ ì„¤ì •"""
        self.team_mapping = {}
        
        # NPB_TEAMSì—ì„œ íŒ€ ë§¤í•‘ ìƒì„±
        for league_teams in NPB_TEAMS.values():
            for team_data in league_teams.values():
                abbr = team_data['abbr']
                # í‚¤ì›Œë“œë“¤ì„ ë§¤í•‘ì— ì¶”ê°€
                for keyword in team_data['keywords']:
                    self.team_mapping[keyword] = abbr
                # íŒ€ëª…ë“¤ë„ ë§¤í•‘ì— ì¶”ê°€
                self.team_mapping[team_data['name_jp']] = abbr
        
    def get_db_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        return psycopg2.connect(**self.db_config)
        
    def convert_team_name(self, team_text: str) -> Optional[str]:
        """íŒ€ëª…ì„ ì•½ì–´ë¡œ ë³€í™˜"""
        team_text = team_text.strip()
        team_text_no_space = re.sub(r'\s+', '', team_text)
        
        # ì§ì ‘ ë§¤ì¹­
        if team_text in self.team_mapping:
            return self.team_mapping[team_text]
        
        # ê³µë°± ì œê±° ë§¤ì¹­
        if team_text_no_space in self.team_mapping:
            return self.team_mapping[team_text_no_space]
        
        # ë¶€ë¶„ ë§¤ì¹­
        for keyword, abbr in self.team_mapping.items():
            keyword_no_space = re.sub(r'\s+', '', keyword)
            if keyword_no_space in team_text_no_space or team_text_no_space in keyword_no_space:
                return abbr
        
        return None
        
    def get_team_id(self, team_abbr: str) -> Optional[int]:
        """íŒ€ ì•½ì–´ë¡œ team_id ì¡°íšŒ"""
        try:
            with self.get_db_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute(
                        "SELECT team_id FROM teams WHERE team_abbreviation = %s", 
                        (team_abbr,)
                    )
                    result = cur.fetchone()
                    return result[0] if result else None
        except Exception:
            return None
            
    def crawl_games(self, date_str: str) -> List[EnhancedGameResult]:
        """í–¥ìƒëœ ê²½ê¸° í¬ë¡¤ë§"""
        year = date_str[:4]
        date_formatted = date_str.replace('-', '')
        url = self.base_url.format(year=year, date=date_formatted)
        
        print(f"ğŸ” Crawling: {date_str}")
        
        try:
            response = self.session.get(url, timeout=CRAWLER_CONFIG['request_timeout'])
            
            if response.status_code == 404:
                print(f"ğŸ“… No games on {date_str}")
                return []
                
            response.raise_for_status()
            response.encoding = 'utf-8'
            soup = BeautifulSoup(response.content, 'html.parser')
            
            games = []
            tables = soup.find_all('table')
            
            # ë””ë²„ê·¸: ì´ í…Œì´ë¸” ìˆ˜
            debug_info = f"Found {len(tables)} tables"
            valid_tables = 0
            
            for i, table in enumerate(tables):
                game = self.parse_enhanced_table(table, date_str, soup)
                if game:
                    games.append(game)
                    valid_tables += 1
                    
            # ë””ë²„ê·¸ ì¶œë ¥ - 6ê²½ê¸° ë¯¸ë§Œì¼ ë•Œë§Œ
            if len(games) < 6:
                print(f"ğŸ” Debug {date_str}: {debug_info}, valid: {valid_tables}")
                    
            print(f"âœ… Found {len(games)} games on {date_str}")
            return games
            
        except Exception as e:
            print(f"âŒ Error crawling {date_str}: {e}")
            return []
    
    def parse_enhanced_table(self, table, date_str: str, soup) -> Optional[EnhancedGameResult]:
        """í…Œì´ë¸”ì—ì„œ í–¥ìƒëœ ê²½ê¸° ì •ë³´ ì¶”ì¶œ"""
        try:
            # ë””ë²„ê¹… ì¶”ê°€
            rows = table.find_all('tr')
            if len(rows) < 2:  # ì¡°ê±´ ì™„í™”: 2í–‰ ì´ìƒ
                print(f"    âŒ í…Œì´ë¸” ê±°ë¶€: {len(rows)}í–‰ (ìµœì†Œ 2í–‰ í•„ìš”)")
                return None
                
            # ì´ë‹ í—¤ë” í™•ì¸ - ë” ê´€ëŒ€í•œ ì¡°ê±´
            header_row = rows[0]
            header_text = header_row.get_text()
            
            # ì¡°ê±´ 1: ì´ë‹ ìˆ«ìê°€ ìˆëŠ”ì§€ í™•ì¸
            has_innings = bool(re.search(r'[ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™123456789]', header_text))
            
            # ì¡°ê±´ 2: ë˜ëŠ” ì•¼êµ¬ ê´€ë ¨ ìš©ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸ 
            has_baseball_terms = bool(re.search(r'[å›åˆè¨ˆRHEæŠ•æ‰‹]', header_text))
            
            if not (has_innings or has_baseball_terms):
                print(f"    âŒ í…Œì´ë¸” ê±°ë¶€: í—¤ë”ì— ì´ë‹/ì•¼êµ¬ìš©ì–´ ì—†ìŒ '{header_text[:50]}'")
                return None
                
            # ì´ë‹ ìˆ˜ ê³„ì‚° - ë” ê´€ëŒ€í•œ ë§¤ì¹­
            header_cells = header_row.find_all(['th', 'td'])
            inning_count = sum(1 for cell in header_cells 
                             if re.match(r'^[ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™1234567891011121314]$', cell.get_text(strip=True)))
            
            is_extra = inning_count > 9
            total_innings = max(inning_count, 9)
            
            # íŒ€ ë°ì´í„° ì¶”ì¶œ - ì¡°ê±´ì„ ë”ìš± ì™„í™”
            team_rows = []
            for row in rows[1:]:
                cells = row.find_all(['td', 'th'])
                cell_count = len(cells)
                
                # ì¡°ê±´ì„ ë‹¨ê³„ì ìœ¼ë¡œ ì™„í™”
                if cell_count >= 8:  # ê¸°ë³¸ ì¡°ê±´
                    team_rows.append(row)
                elif cell_count >= 6:  # ì™„í™”ëœ ì¡°ê±´
                    # ì²« ë²ˆì§¸ ì…€ì´ íŒ€ëª…ì²˜ëŸ¼ ë³´ì´ëŠ”ì§€ í™•ì¸ - ë” ê´€ëŒ€í•˜ê²Œ
                    first_cell = cells[0].get_text(strip=True)
                    # ì „ê°ë¬¸ì ì²˜ë¦¬ ë° ë” ë§ì€ í‚¤ì›Œë“œ ì¶”ê°€
                    team_keywords = ['å·¨äºº', 'é˜ªç¥', 'DeNA', 'ï¼¤ï½…ï¼®ï¼¡', 'åºƒå³¶', 'åºƒ  å³¶', 'ä¸­æ—¥', 'ãƒ¤ã‚¯ãƒ«ãƒˆ', 
                                   'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯', 'ãƒ­ãƒƒãƒ†', 'æ¥½å¤©', 'ã‚ªãƒªãƒƒã‚¯ã‚¹', 'è¥¿æ­¦', 'æ—¥æœ¬ãƒãƒ ', 'ã‚¸ãƒ£ã‚¤ã‚¢ãƒ³ãƒ„',
                                   'ã‚¿ã‚¤ã‚¬ãƒ¼ã‚¹', 'ãƒ™ã‚¤ã‚¹ã‚¿ãƒ¼ã‚º', 'ã‚«ãƒ¼ãƒ—', 'ãƒ‰ãƒ©ã‚´ãƒ³ã‚º', 'ã‚¹ãƒ¯ãƒ­ãƒ¼ã‚º', 'ãƒ›ãƒ¼ã‚¯ã‚¹',
                                   'ãƒãƒªãƒ¼ãƒ³ã‚º', 'ã‚¤ãƒ¼ã‚°ãƒ«ã‚¹', 'ãƒãƒ•ã‚¡ãƒ­ãƒ¼ã‚º', 'ãƒ©ã‚¤ã‚ªãƒ³ã‚º', 'ãƒ•ã‚¡ã‚¤ã‚¿ãƒ¼ã‚º']
                    if any(team in first_cell for team in team_keywords):
                        team_rows.append(row)
            
            # ë””ë²„ê·¸: ìƒì„¸ ì •ë³´
            if len(team_rows) < 2:
                all_row_info = []
                for i, row in enumerate(rows[1:], 1):
                    cells = row.find_all(['td', 'th'])
                    first_cell = cells[0].get_text(strip=True) if cells else ""
                    all_row_info.append(f"í–‰{i}: {len(cells)}ì…€, '{first_cell}'")
                
                print(f"ğŸ” í…Œì´ë¸” ê±°ë¶€ë¨ - íŒ€í–‰: {len(team_rows)}ê°œ")
                print(f"    ì „ì²´ í–‰ ì •ë³´: {all_row_info}")
                return None
            
            # 2ê°œê°€ ì•„ë‹ˆì–´ë„ ìµœì†Œ 2ê°œ ì´ìƒì´ë©´ ì‹œë„
            if len(team_rows) < 2:
                return None
                
            # ê°€ì¥ ìœ ë ¥í•œ 2ê°œ í–‰ ì„ íƒ (ì…€ ìˆ˜ê°€ ë§ì€ ìˆœ)
            team_rows = sorted(team_rows, key=lambda r: len(r.find_all(['td', 'th'])), reverse=True)[:2]
                
            away_row, home_row = team_rows[0], team_rows[1]
            
            # ì–´ì›¨ì´íŒ€ ì •ë³´
            away_cells = away_row.find_all(['td', 'th'])
            away_team_text = away_cells[0].get_text(strip=True)
            away_team = self.convert_team_name(away_team_text)
            away_total_score = int(away_cells[-1].get_text(strip=True))
            away_inning_scores = self.extract_inning_scores(away_cells)
            
            # í™ˆíŒ€ ì •ë³´  
            home_cells = home_row.find_all(['td', 'th'])
            home_team_text = home_cells[0].get_text(strip=True)
            home_team = self.convert_team_name(home_team_text)
            home_total_score = self.calculate_home_score(home_cells)
            home_inning_scores = self.extract_inning_scores(home_cells)
            
            if not away_team or not home_team:
                return None
                
            # ê²½ê¸° ìƒíƒœ ë° íŠ¹ìˆ˜ ìƒí™© íŒë‹¨
            game_status = self.determine_game_status(soup)
            is_draw = (away_total_score == home_total_score and game_status == "completed")
            is_cancelled = "cancelled" in game_status
            
            game = EnhancedGameResult(
                game_date=date_str,
                home_team=home_team,
                away_team=away_team,
                home_score=home_total_score,
                away_score=away_total_score,
                game_status=game_status,
                is_extra_innings=is_extra,
                total_innings=total_innings,
                is_draw=is_draw,
                is_cancelled=is_cancelled,
                home_inning_scores=home_inning_scores,
                away_inning_scores=away_inning_scores
            )
            
            return game
            
        except Exception as e:
            return None
    
    def calculate_home_score(self, home_cells) -> int:
        """í™ˆíŒ€ ì ìˆ˜ ê³„ì‚° (X ì²˜ë¦¬)"""
        home_score_text = home_cells[-1].get_text(strip=True)
        
        if 'X' in home_score_text:
            # ì´ë‹ë³„ ì ìˆ˜ í•©ì‚°
            total = 0
            for cell in home_cells[1:-1]:
                cell_text = cell.get_text(strip=True)
                if cell_text and cell_text != 'X' and cell_text.isdigit():
                    total += int(cell_text)
            return total
        else:
            if home_score_text.isdigit():
                return int(home_score_text)
            else:
                numbers = re.findall(r'\\d+', home_score_text)
                return int(numbers[0]) if numbers else 0
    
    def extract_inning_scores(self, cells) -> List[int]:
        """ì´ë‹ë³„ ì ìˆ˜ ì¶”ì¶œ"""
        scores = []
        for cell in cells[1:-1]:  # íŒ€ëª…ê³¼ ê³„ ì œì™¸
            cell_text = cell.get_text(strip=True)
            if cell_text == 'X':
                break
            elif cell_text.isdigit():
                scores.append(int(cell_text))
            else:
                scores.append(0)
        return scores
    
    def determine_game_status(self, soup) -> str:
        """ê²½ê¸° ìƒíƒœ íŒë‹¨"""
        page_text = soup.get_text()
        
        if 'ä¸­æ­¢' in page_text or 'å»¶æœŸ' in page_text:
            return "cancelled" 
        elif 'é€²è¡Œä¸­' in page_text:
            return "in_progress"
        else:
            return "completed"
    
    def save_games_to_db(self, games: List[EnhancedGameResult]) -> bool:
        """í–¥ìƒëœ ê²½ê¸° ë°ì´í„°ë¥¼ DBì— ì €ì¥"""
        if not games:
            return True
            
        try:
            with self.get_db_connection() as conn:
                with conn.cursor() as cur:
                    saved_count = 0
                    
                    for game in games:
                        home_team_id = self.get_team_id(game.home_team)
                        away_team_id = self.get_team_id(game.away_team)
                        
                        if not home_team_id or not away_team_id:
                            print(f"âš ï¸ Team IDs not found: {game.home_team}, {game.away_team}")
                            continue
                        
                        game_data = game.to_db_dict()
                        
                        # UPSERT ì¿¼ë¦¬
                        values = (
                            home_team_id, away_team_id, game_data['game_date'],
                            game_data['home_score'], game_data['away_score'], game_data['game_status'],
                            game_data['is_extra_innings'], game_data['total_innings'], 
                            game_data['is_draw'], game_data['is_cancelled'],
                            game_data['stadium'], game_data['game_start_time'],
                            game_data['home_inning_scores'], game_data['away_inning_scores']
                        )
                        
                        cur.execute("""
                            INSERT INTO games (
                                home_team_id, away_team_id, game_date,
                                home_score, away_score, game_status,
                                is_extra_innings, total_innings, is_draw, is_cancelled,
                                stadium, game_start_time, 
                                home_inning_scores, away_inning_scores
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                            ON CONFLICT ON CONSTRAINT unique_game_date_teams
                            DO UPDATE SET
                                home_score = EXCLUDED.home_score,
                                away_score = EXCLUDED.away_score,  
                                game_status = EXCLUDED.game_status,
                                is_extra_innings = EXCLUDED.is_extra_innings,
                                total_innings = EXCLUDED.total_innings,
                                is_draw = EXCLUDED.is_draw,
                                is_cancelled = EXCLUDED.is_cancelled,
                                stadium = EXCLUDED.stadium,
                                game_start_time = EXCLUDED.game_start_time,
                                home_inning_scores = EXCLUDED.home_inning_scores,
                                away_inning_scores = EXCLUDED.away_inning_scores,
                                updated_at = CURRENT_TIMESTAMP
                        """, values)
                        
                        saved_count += 1
                    
                    conn.commit()
                    print(f"âœ… Saved {saved_count} games to database")
                    return True
                    
        except Exception as e:
            print(f"âŒ Database save failed: {e}")
            return False
    
    def update_standings_from_games(self) -> bool:
        """ê²½ê¸° ê²°ê³¼ë¡œë¶€í„° ìˆœìœ„í‘œ ì—…ë°ì´íŠ¸"""
        try:
            with self.get_db_connection() as conn:
                with conn.cursor() as cur:
                    print("ğŸ“Š Updating standings from game results...")
                    
                    # í˜„ì¬ ì‹œì¦Œ ìˆœìœ„í‘œ ì‚­ì œ
                    cur.execute("DELETE FROM standings WHERE season_year = %s", (self.season_year,))
                    
                    # ê²½ê¸° ê²°ê³¼ë¡œë¶€í„° ìˆœìœ„ ê³„ì‚°
                    cur.execute("""
                        WITH team_stats AS (
                            SELECT 
                                t.team_id,
                                t.team_abbreviation,
                                t.league,
                                COUNT(*) as games_played,
                                COUNT(*) FILTER (WHERE 
                                    (g.home_team_id = t.team_id AND g.home_score > g.away_score) OR
                                    (g.away_team_id = t.team_id AND g.away_score > g.home_score)
                                ) as wins,
                                COUNT(*) FILTER (WHERE 
                                    (g.home_team_id = t.team_id AND g.home_score < g.away_score) OR
                                    (g.away_team_id = t.team_id AND g.away_score < g.home_score)
                                ) as losses,
                                COUNT(*) FILTER (WHERE g.is_draw) as draws,
                                SUM(CASE WHEN g.home_team_id = t.team_id THEN g.home_score ELSE g.away_score END) as runs_scored,
                                SUM(CASE WHEN g.home_team_id = t.team_id THEN g.away_score ELSE g.home_score END) as runs_allowed
                            FROM teams t
                            LEFT JOIN games g ON (g.home_team_id = t.team_id OR g.away_team_id = t.team_id)
                            WHERE EXTRACT(YEAR FROM g.game_date) = %s AND g.game_status = 'completed'
                            GROUP BY t.team_id, t.team_abbreviation, t.league
                        ),
                        league_leaders AS (
                            SELECT 
                                league,
                                MAX(CASE WHEN wins + losses > 0 THEN wins::NUMERIC / (wins + losses) ELSE 0 END) as leader_pct,
                                MAX(wins) as leader_wins,
                                MIN(losses) as leader_losses
                            FROM team_stats
                            GROUP BY league
                        )
                        INSERT INTO standings (
                            team_id, season_year, league, position_rank, games_played, wins, losses, draws,
                            win_percentage, games_behind, runs_scored, runs_allowed, run_differential,
                            updated_at
                        )
                        SELECT 
                            ts.team_id,
                            %s as season_year,
                            ts.league,
                            ROW_NUMBER() OVER (
                                PARTITION BY ts.league 
                                ORDER BY 
                                    CASE WHEN ts.wins + ts.losses > 0 THEN ts.wins::NUMERIC / (ts.wins + ts.losses) ELSE 0 END DESC,
                                    ts.wins DESC,
                                    ts.losses ASC
                            ) as rank,
                            ts.games_played,
                            ts.wins,
                            ts.losses, 
                            ts.draws,
                            CASE WHEN ts.wins + ts.losses > 0 THEN ts.wins::NUMERIC / (ts.wins + ts.losses) ELSE 0 END as win_percentage,
                            ((ll.leader_wins - ts.wins) + (ts.losses - ll.leader_losses))::NUMERIC / 2.0 as games_behind,
                            ts.runs_scored,
                            ts.runs_allowed,
                            ts.runs_scored - ts.runs_allowed as run_differential,
                            CURRENT_TIMESTAMP
                        FROM team_stats ts
                        JOIN league_leaders ll ON ts.league = ll.league
                        ORDER BY ts.league, win_percentage DESC
                    """, (self.season_year, self.season_year))
                    
                    updated_count = cur.rowcount
                    conn.commit()
                    
                    print(f"âœ… Updated standings for {updated_count} teams")
                    return True
                    
        except Exception as e:
            print(f"âŒ Standings update failed: {e}")
            return False
    
    def setup_file_logging(self):
        """íŒŒì¼ ë¡œê¹… ì„¤ì •"""
        import logging
        from datetime import datetime
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        log_dir = os.path.join(os.path.dirname(__file__), 'logs')
        os.makedirs(log_dir, exist_ok=True)
        
        # ë¡œê·¸ íŒŒì¼ëª… (ë‚ ì§œë³„)
        log_filename = f"crawler_{datetime.now().strftime('%Y%m%d')}.log"
        log_file = os.path.join(log_dir, log_filename)
        
        # ë¡œê±° ì„¤ì •
        logger = logging.getLogger('NPBCrawler')
        logger.setLevel(logging.INFO)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        file_handler.setFormatter(formatter)
        
        # ì¤‘ë³µ í•¸ë“¤ëŸ¬ ë°©ì§€
        if not logger.handlers:
            logger.addHandler(file_handler)
        
        self.logger = logger

    def log_crawl_activity(self, status: str, message: str, records_count: int = 0):
        """í¬ë¡¤ë§ í™œë™ ë¡œê·¸"""
        # íŒŒì¼ ë¡œê·¸
        if hasattr(self, 'logger'):
            self.logger.info(f"Status: {status}, Records: {records_count}, Message: {message}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ ë¡œê·¸
        try:
            with self.get_db_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute("""
                        INSERT INTO crawl_logs (
                            source_name, crawl_status, records_processed,
                            error_message, crawl_timestamp
                        ) VALUES (%s, %s, %s, %s, CURRENT_TIMESTAMP)
                    """, ('NPB_ENHANCED', status, records_count, message))
                    conn.commit()
        except Exception as e:
            if hasattr(self, 'logger'):
                self.logger.error(f"Failed to log to database: {e}")
            pass
            
    def run_crawl(self, days_back: int = 7) -> bool:
        """í–¥ìƒëœ ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰"""
        start_time = datetime.now()
        print(f"ğŸš€ Starting NPB crawl for last {days_back} days...")
        
        try:
            all_games = []
            jst_now = datetime.now(self.jst)
            
            # ë‚ ì§œ ë²”ìœ„ ìƒì„±
            for i in range(days_back):
                date = jst_now - timedelta(days=i)
                date_str = date.strftime('%Y-%m-%d')
                
                games = self.crawl_games(date_str)
                all_games.extend(games)
                
                # ìš”ì²­ ê°„ê²©
                time.sleep(DATA_SOURCES['nikkansports']['rate_limit'])
            
            # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
            save_success = self.save_games_to_db(all_games)
            standings_success = self.update_standings_from_games()
            
            # í¬ë¡¤ë§ í†µê³„
            duration = datetime.now() - start_time
            total_records = len(all_games)
            
            # íŠ¹ìˆ˜ ê²½ê¸° í†µê³„
            extra_games = [g for g in all_games if g.is_extra_innings]
            draw_games = [g for g in all_games if g.is_draw]
            cancelled_games = [g for g in all_games if g.is_cancelled]
            
            print(f"\\nğŸ† **CRAWL SUMMARY**")
            print(f"Total games: {total_records}")
            print(f"ì—°ì¥ì „: {len(extra_games)}")
            print(f"ë¬´ìŠ¹ë¶€: {len(draw_games)}")
            print(f"ì·¨ì†Œ/ì—°ê¸°: {len(cancelled_games)}")
            print(f"Duration: {duration.total_seconds():.1f}s")
            
            # ë¡œê·¸ ê¸°ë¡
            status = 'success' if (save_success and standings_success) else 'partial'
            self.log_crawl_activity(status, f'Crawl: {total_records} games', total_records)
            
            return save_success and standings_success
            
        except Exception as e:
            error_msg = f"Crawl failed: {e}"
            print(f"âŒ {error_msg}")
            self.log_crawl_activity('error', error_msg, 0)
            return False
    
    def crawl_full_season(self):
        """NPB 2025 ì‹œì¦Œ ì „ì²´ í¬ë¡¤ë§"""
        # NPB ì‹œì¦Œ ì¼ë°˜ì ìœ¼ë¡œ 3ì›” ë§ ~ 10ì›” ì´ˆ
        season_start = datetime(2025, 3, 20)
        season_end = datetime(2025, 10, 15)
        
        print(f"ğŸŸï¸ NPB 2025 ì‹œì¦Œ ì „ì²´ í¬ë¡¤ë§ ì‹œì‘")
        print(f"ğŸ“… ê¸°ê°„: {season_start.strftime('%Y-%m-%d')} ~ {season_end.strftime('%Y-%m-%d')}")
        
        current_date = season_start
        total_games = 0
        total_days = (season_end - season_start).days + 1
        processed_days = 0
        
        while current_date <= season_end:
            date_str = current_date.strftime('%Y-%m-%d')
            
            # ì§„í–‰ë¥  í‘œì‹œ
            processed_days += 1
            progress = (processed_days / total_days) * 100
            print(f"\nğŸ”„ [{processed_days:3d}/{total_days}] ({progress:5.1f}%) - {date_str}")
            
            try:
                games = self.crawl_games(date_str)
                if games:
                    save_success = self.save_games_to_db(games)
                    if save_success:
                        total_games += len(games)
                        print(f"âœ… {len(games)} games saved")
                    else:
                        print(f"âŒ Failed to save {len(games)} games")
                else:
                    print("ğŸ“… No games")
                
                # ë§¤ì£¼ ì¼ìš”ì¼ë§ˆë‹¤ ìˆœìœ„í‘œ ì—…ë°ì´íŠ¸
                if current_date.weekday() == 6:  # ì¼ìš”ì¼
                    print("ğŸ“Š Weekly standings update...")
                    self.update_standings_from_games()
                
                # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                time.sleep(1)
                
            except Exception as e:
                print(f"âŒ Error on {date_str}: {e}")
                continue
            
            current_date += timedelta(days=1)
        
        # ìµœì¢… ìˆœìœ„í‘œ ì—…ë°ì´íŠ¸
        print("\nğŸ“Š Final standings update...")
        standings_success = self.update_standings_from_games()
        
        print(f"\nğŸ† **SEASON CRAWL COMPLETE**")
        print(f"Total games collected: {total_games}")
        print(f"Standings updated: {'âœ…' if standings_success else 'âŒ'}")
        print(f"Duration: {(datetime.now() - season_start).days} days processed")
        
        return total_games > 0

def main():
    """ë©”ì¸ ì‹¤í–‰"""
    crawler = NPBCrawler()
    
    try:
        if len(sys.argv) > 1:
            if sys.argv[1] == '--test':
                print("ğŸ§ª Running test crawl (3 days)...")
                success = crawler.run_crawl(days_back=3)
            elif sys.argv[1] == '--season':
                print("ğŸŸï¸ Running FULL SEASON crawl (March - October 2025)...")
                success = crawler.crawl_full_season()
            else:
                days = int(sys.argv[1])
                print(f"ğŸš€ Running crawl ({days} days)...")
                success = crawler.run_crawl(days_back=days)
        else:
            print("ğŸš€ Running full crawl (7 days)...")
            success = crawler.run_crawl(days_back=7)
        
        sys.exit(0 if success else 1)
        
    except KeyboardInterrupt:
        print("\\nâ¹ï¸ Crawl interrupted by user")
    except Exception as e:
        print(f"âŒ Crawler failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()