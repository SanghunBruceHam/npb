#!/usr/bin/env python3
"""
NPB Simple Crawler - ì§ì ‘ TXT ì €ì¥ ë°©ì‹
í¬ë¡¤ë§ â†’ TXT ì €ì¥ â†’ JavaScript ì²˜ë¦¬ â†’ JSON
"""

try:
    import requests
    from bs4 import BeautifulSoup
    CRAWLING_ENABLED = True
except ImportError:
    print("âš ï¸ Web crawling dependencies not available (requests, beautifulsoup4)")
    print("ğŸ“„ Using existing data conversion instead...")
    CRAWLING_ENABLED = False
    requests = None
    BeautifulSoup = None

# Optional Selenium support (dynamic pages)
try:
    from selenium import webdriver
    from selenium.webdriver.chrome.options import Options as ChromeOptions
    from selenium.webdriver.common.by import By
    from selenium.webdriver.support.ui import WebDriverWait
    from selenium.webdriver.support import expected_conditions as EC
    from webdriver_manager.chrome import ChromeDriverManager
    SELENIUM_AVAILABLE = True
except Exception:
    SELENIUM_AVAILABLE = False

import json
import os
from datetime import datetime, timedelta
from pathlib import Path
import time
import logging
import sys
import re

class SimpleCrawler:
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.data_dir = self.project_root / "data" / "simple"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        self.setup_logging()
        
        # NPB íŒ€ ì •ë³´ (ì›¹ì‚¬ì´íŠ¸ í‘œì‹œëª… ê¸°ì¤€)
        self.teams = {
            # ì„¼íŠ¸ëŸ´ë¦¬ê·¸
            'ã‚¸ãƒ£ã‚¤ã‚¢ãƒ³ãƒ„': {'id': 1, 'abbr': 'YOG', 'name': 'èª­å£²ã‚¸ãƒ£ã‚¤ã‚¢ãƒ³ãƒ„', 'league': 'Central'},
            'å·¨äºº': {'id': 1, 'abbr': 'YOG', 'name': 'èª­å£²ã‚¸ãƒ£ã‚¤ã‚¢ãƒ³ãƒ„', 'league': 'Central'},
            'å·¨': {'id': 1, 'abbr': 'YOG', 'name': 'èª­å£²ã‚¸ãƒ£ã‚¤ã‚¢ãƒ³ãƒ„', 'league': 'Central'},  # NPB ì¶•ì•½í˜•
            'é˜ªç¥': {'id': 2, 'abbr': 'HAN', 'name': 'é˜ªç¥ã‚¿ã‚¤ã‚¬ãƒ¼ã‚¹', 'league': 'Central'},
            'ç¥': {'id': 2, 'abbr': 'HAN', 'name': 'é˜ªç¥ã‚¿ã‚¤ã‚¬ãƒ¼ã‚¹', 'league': 'Central'},  # NPB 1ë¬¸ì í‘œê¸°
            'é˜ª': {'id': 2, 'abbr': 'HAN', 'name': 'é˜ªç¥ã‚¿ã‚¤ã‚¬ãƒ¼ã‚¹', 'league': 'Central'},  # NPB ì¶•ì•½í˜•
            'ï¼¤ï½…ï¼®ï¼¡': {'id': 3, 'abbr': 'YDB', 'name': 'æ¨ªæµœDeNAãƒ™ã‚¤ã‚¹ã‚¿ãƒ¼ã‚º', 'league': 'Central'},
            'DeNA': {'id': 3, 'abbr': 'YDB', 'name': 'æ¨ªæµœDeNAãƒ™ã‚¤ã‚¹ã‚¿ãƒ¼ã‚º', 'league': 'Central'},
            'ãƒ‡': {'id': 3, 'abbr': 'YDB', 'name': 'æ¨ªæµœDeNAãƒ™ã‚¤ã‚¹ã‚¿ãƒ¼ã‚º', 'league': 'Central'},
            'ï¼¤': {'id': 3, 'abbr': 'YDB', 'name': 'æ¨ªæµœDeNAãƒ™ã‚¤ã‚¹ã‚¿ãƒ¼ã‚º', 'league': 'Central'},  # NPB ì¶•ì•½í˜•
            'ä¸­æ—¥': {'id': 5, 'abbr': 'CHU', 'name': 'ä¸­æ—¥ãƒ‰ãƒ©ã‚´ãƒ³ã‚º', 'league': 'Central'},
            'ä¸­': {'id': 5, 'abbr': 'CHU', 'name': 'ä¸­æ—¥ãƒ‰ãƒ©ã‚´ãƒ³ã‚º', 'league': 'Central'},  # NPB ì¶•ì•½í˜•
            'åºƒå³¶': {'id': 4, 'abbr': 'HIR', 'name': 'åºƒå³¶æ±æ´‹ã‚«ãƒ¼ãƒ—', 'league': 'Central'},
            'åºƒ': {'id': 4, 'abbr': 'HIR', 'name': 'åºƒå³¶æ±æ´‹ã‚«ãƒ¼ãƒ—', 'league': 'Central'},  # NPB ì¶•ì•½í˜•
            'ãƒ¤ã‚¯ãƒ«ãƒˆ': {'id': 6, 'abbr': 'YAK', 'name': 'æ±äº¬ãƒ¤ã‚¯ãƒ«ãƒˆã‚¹ãƒ¯ãƒ­ãƒ¼ã‚º', 'league': 'Central'},
            'ãƒ¤': {'id': 6, 'abbr': 'YAK', 'name': 'æ±äº¬ãƒ¤ã‚¯ãƒ«ãƒˆã‚¹ãƒ¯ãƒ­ãƒ¼ã‚º', 'league': 'Central'},  # NPB ì¶•ì•½í˜•
            
            # í¼ì‹œí”½ë¦¬ê·¸
            'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯': {'id': 7, 'abbr': 'SOF', 'name': 'ç¦å²¡ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ãƒ›ãƒ¼ã‚¯ã‚¹', 'league': 'Pacific'},
            'ã‚½': {'id': 7, 'abbr': 'SOF', 'name': 'ç¦å²¡ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ãƒ›ãƒ¼ã‚¯ã‚¹', 'league': 'Pacific'},  # NPB ì¶•ì•½í˜•
            'ãƒ­ãƒƒãƒ†': {'id': 8, 'abbr': 'LOT', 'name': 'åƒè‘‰ãƒ­ãƒƒãƒ†ãƒãƒªãƒ¼ãƒ³ã‚º', 'league': 'Pacific'},
            'ãƒ­': {'id': 8, 'abbr': 'LOT', 'name': 'åƒè‘‰ãƒ­ãƒƒãƒ†ãƒãƒªãƒ¼ãƒ³ã‚º', 'league': 'Pacific'},  # NPB ì¶•ì•½í˜•
            'æ¥½å¤©': {'id': 9, 'abbr': 'RAK', 'name': 'æ±åŒ—æ¥½å¤©ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¤ãƒ¼ã‚°ãƒ«ã‚¹', 'league': 'Pacific'},
            'æ¥½': {'id': 9, 'abbr': 'RAK', 'name': 'æ±åŒ—æ¥½å¤©ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¤ãƒ¼ã‚°ãƒ«ã‚¹', 'league': 'Pacific'},  # NPB ì¶•ì•½í˜•
            'ã‚ªãƒªãƒƒã‚¯ã‚¹': {'id': 10, 'abbr': 'ORI', 'name': 'ã‚ªãƒªãƒƒã‚¯ã‚¹ãƒãƒ•ã‚¡ãƒ­ãƒ¼ã‚º', 'league': 'Pacific'},
            'ã‚ª': {'id': 10, 'abbr': 'ORI', 'name': 'ã‚ªãƒªãƒƒã‚¯ã‚¹ãƒãƒ•ã‚¡ãƒ­ãƒ¼ã‚º', 'league': 'Pacific'},  # NPB ì¶•ì•½í˜•
            'è¥¿æ­¦': {'id': 11, 'abbr': 'SEI', 'name': 'åŸ¼ç‰è¥¿æ­¦ãƒ©ã‚¤ã‚ªãƒ³ã‚º', 'league': 'Pacific'},
            'è¥¿': {'id': 11, 'abbr': 'SEI', 'name': 'åŸ¼ç‰è¥¿æ­¦ãƒ©ã‚¤ã‚ªãƒ³ã‚º', 'league': 'Pacific'},  # NPB ì¶•ì•½í˜•
            'æ—¥æœ¬ãƒãƒ ': {'id': 12, 'abbr': 'NIP', 'name': 'åŒ—æµ·é“æ—¥æœ¬ãƒãƒ ãƒ•ã‚¡ã‚¤ã‚¿ãƒ¼ã‚º', 'league': 'Pacific'},
            'æ—¥': {'id': 12, 'abbr': 'NIP', 'name': 'åŒ—æµ·é“æ—¥æœ¬ãƒãƒ ãƒ•ã‚¡ã‚¤ã‚¿ãƒ¼ã‚º', 'league': 'Pacific'}  # NPB ì¶•ì•½í˜•
        }

        # í™ˆíŒ€ ê¸°ë³¸ êµ¬ì¥ ë§¤í•‘ (í‘œì‹œìš© ì¶”ì •ì¹˜)
        self.default_stadium_by_abbr = {
            'YOG': 'æ±äº¬ãƒ‰ãƒ¼ãƒ ',
            'HAN': 'é˜ªç¥ç”²å­åœ’çƒå ´',
            'CHU': 'ãƒãƒ³ãƒ†ãƒªãƒ³ãƒ‰ãƒ¼ãƒ  ãƒŠã‚´ãƒ¤',
            'YDB': 'æ¨ªæµœã‚¹ã‚¿ã‚¸ã‚¢ãƒ ',
            'HIR': 'MAZDA Zoom-Zoom ã‚¹ã‚¿ã‚¸ã‚¢ãƒ åºƒå³¶',
            'YAK': 'æ˜æ²»ç¥å®®é‡çƒå ´',
            'SOF': 'ç¦å²¡PayPayãƒ‰ãƒ¼ãƒ ',
            'LOT': 'ZOZOãƒãƒªãƒ³ã‚¹ã‚¿ã‚¸ã‚¢ãƒ ',
            'SEI': 'ãƒ™ãƒ«ãƒ¼ãƒŠãƒ‰ãƒ¼ãƒ ',
            'ORI': 'äº¬ã‚»ãƒ©ãƒ‰ãƒ¼ãƒ å¤§é˜ª',
            'NIP': 'ã‚¨ã‚¹ã‚³ãƒ³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰HOKKAIDO',
            'RAK': 'æ¥½å¤©ãƒ¢ãƒã‚¤ãƒ«ãƒ‘ãƒ¼ã‚¯å®®åŸ',
        }
        # Preferred Japanese short labels by team abbr
        self.abbr_to_ja_short = {
            'YOG': 'å·¨äºº',
            'HAN': 'é˜ªç¥',
            'YDB': 'ï¼¤ï½…ï¼®ï¼¡',
            'HIR': 'åºƒå³¶',
            'CHU': 'ä¸­æ—¥',
            'YAK': 'ãƒ¤ã‚¯ãƒ«ãƒˆ',
            'SOF': 'ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯',
            'LOT': 'ãƒ­ãƒƒãƒ†',
            'RAK': 'æ¥½å¤©',
            'ORI': 'ã‚ªãƒªãƒƒã‚¯ã‚¹',
            'SEI': 'è¥¿æ­¦',
            'NIP': 'æ—¥æœ¬ãƒãƒ ',
        }
        # Canonical IDâ†’Team mapping for validation/repair
        self.id_to_team = {
            1: {'abbr': 'YOG', 'league': 'Central'},
            2: {'abbr': 'HAN', 'league': 'Central'},
            3: {'abbr': 'YDB', 'league': 'Central'},
            4: {'abbr': 'HIR', 'league': 'Central'},
            5: {'abbr': 'CHU', 'league': 'Central'},
            6: {'abbr': 'YAK', 'league': 'Central'},
            7: {'abbr': 'SOF', 'league': 'Pacific'},
            8: {'abbr': 'LOT', 'league': 'Pacific'},
            9: {'abbr': 'RAK', 'league': 'Pacific'},
            10: {'abbr': 'ORI', 'league': 'Pacific'},
            11: {'abbr': 'SEI', 'league': 'Pacific'},
            12: {'abbr': 'NIP', 'league': 'Pacific'},
        }
        self.valid_abbrs = {v['abbr'] for v in self.id_to_team.values()}
        self.valid_leagues = {'Central', 'Pacific'}
        # Selenium driver holder
        self._driver = None
        self.use_selenium = (os.environ.get('USE_SELENIUM') == '1') and SELENIUM_AVAILABLE
    
    def setup_logging(self):
        log_dir = self.project_root / "logs" / "simple_crawler"
        log_dir.mkdir(parents=True, exist_ok=True)
        
        log_file = log_dir / f"crawler_{datetime.now().strftime('%Y%m%d')}.log"
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger('simple_crawler')

    # ===== Selenium helpers =====
    def ensure_driver(self):
        if not SELENIUM_AVAILABLE:
            return None
        if self._driver is not None:
            return self._driver
        try:
            from selenium.webdriver.chrome.service import Service as ChromeService
            options = ChromeOptions()
            options.add_argument('--headless=new')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')
            options.add_argument('--window-size=1280,800')
            service = ChromeService(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=options)
            self._driver = driver
            self.logger.info('ğŸ§­ Selenium Chrome driver initialized')
            return driver
        except Exception as e:
            self.logger.warning(f"âš ï¸ Selenium init failed: {e}")
            return None

    def fetch_soup(self, url, wait_css=None, timeout=15):
        """Fetch URL and return BeautifulSoup; try requests first, fallback to Selenium when configured/needed."""
        # Try requests
        try:
            headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36'}
            resp = requests.get(url, timeout=timeout, headers=headers)
            if resp.status_code == 200 and resp.content:
                return BeautifulSoup(resp.content, 'html.parser')
            self.logger.info(f"â„¹ï¸ requests returned {resp.status_code} for {url}, considering Selenium fallback")
        except Exception as e:
            self.logger.info(f"â„¹ï¸ requests failed for {url}: {e}")

        # Fallback to Selenium when available/desired
        if not SELENIUM_AVAILABLE:
            return None
        driver = self.ensure_driver()
        if driver is None:
            return None
        try:
            driver.get(url)
            if wait_css:
                WebDriverWait(driver, timeout).until(EC.presence_of_element_located((By.CSS_SELECTOR, wait_css)))
            html = driver.page_source
            return BeautifulSoup(html, 'html.parser')
        except Exception as e:
            self.logger.warning(f"âš ï¸ Selenium fetch failed: {e}")
            return None
    
    def get_team_info(self, team_name):
        """íŒ€ëª…ìœ¼ë¡œ íŒ€ ì •ë³´ ì°¾ê¸°"""
        for key, info in self.teams.items():
            if key in team_name:
                return info
        return None
    
    def convert_existing_data_to_txt(self):
        """ê¸°ì¡´ JSON â†’ TXT ì—­ë³€í™˜ (í¬ë¡¤ë§ ë¶ˆê°€ ì‹œ fallback)"""
        self.logger.info("ğŸ“„ Converting existing JSON data to TXT format (fallback)...")
        
        try:
            # Use existing json_to_txt_converter script
            json_to_txt = self.project_root / 'scripts' / 'json_to_txt_converter.py'
            if json_to_txt.exists():
                result = os.system(f"cd {self.project_root} && python3 {json_to_txt}")
                if result == 0:
                    self.logger.info("âœ… JSON to TXT conversion completed")
                    return True
                else:
                    self.logger.error("âŒ JSON to TXT conversion failed")
                    return False
            else:
                # If converter not present, try to proceed with existing TXT files
                games_txt = self.data_dir / 'games_raw.txt'
                teams_txt = self.data_dir / 'teams_raw.txt'
                if games_txt.exists() and teams_txt.exists():
                    self.logger.info("âš ï¸ Converter not found, but TXT files already exist. Proceeding.")
                    return True
                self.logger.error("âŒ JSON to TXT converter not found and TXT files missing")
                return False
                
        except Exception as e:
            self.logger.error(f"âŒ JSONâ†’TXT conversion error: {e}")
            return False

    def crawl_date(self, target_date):
        """íŠ¹ì • ë‚ ì§œì˜ ê²½ê¸° ê²°ê³¼ í¬ë¡¤ë§"""
        if not CRAWLING_ENABLED:
            return []  # Skip actual crawling if dependencies unavailable
            
        self.logger.info(f"ğŸ” Crawling: {target_date.strftime('%Y-%m-%d')}")
        
        # 1. NPB ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ ê²½ê¸° ì •ë³´ ì‹œë„
        games = self.crawl_game_detail(target_date)
        
        # 2. NPBì—ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìœ¼ë©´ ë‹›ì¹¸ìŠ¤í¬ì¸ ì—ì„œ ì‹œë„
        if not games:
            games = self.crawl_from_nikkansports(target_date)
        
        # 3. ê²½ê¸° ìƒíƒœ ë¡œê·¸ ì¶œë ¥
        for game in games:
            if game.get('status') == 'completed':
                self.logger.info(f"âœ… Completed: {game['away_team_abbr']} {game.get('away_score', 0)}-{game.get('home_score', 0)} {game['home_team_abbr']}")
            elif game.get('status') == 'postponed':
                self.logger.info(f"â¸ï¸ Postponed: {game['away_team_abbr']} vs {game['home_team_abbr']}")
            else:
                self.logger.info(f"ğŸ“… Scheduled: {game['away_team_abbr']} vs {game['home_team_abbr']}")
        
        self.logger.info(f"âœ… Found {len(games)} games on {target_date.strftime('%Y-%m-%d')}")
        return games
        
    def crawl_from_nikkansports(self, target_date):
        """ë‹›ì¹¸ìŠ¤í¬ì¸ ì—ì„œ ê²½ê¸° ê²°ê³¼ í¬ë¡¤ë§ (ê¸°ì¡´ ë°©ì‹)"""
        # URL í˜•ì‹: https://www.nikkansports.com/baseball/professional/score/2025/pf-score-20250328.html
        date_str = target_date.strftime("%Y%m%d")
        year = target_date.strftime("%Y")
        url = f"https://www.nikkansports.com/baseball/professional/score/{year}/pf-score-{date_str}.html"
        
        self.logger.info(f"ğŸ“° Trying Nikkansports: {target_date.strftime('%Y-%m-%d')}")
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36'
            }
            response = requests.get(url, timeout=15, headers=headers)
            response.raise_for_status()
            # Use raw content so BeautifulSoup can detect meta charset correctly
            soup = BeautifulSoup(response.content, 'html.parser')
            games = []
            # Keep track of parsed games to prevent duplicates while preferring richer entries
            strict_games = {}
            symmetric_map = {}

            def build_symmetric_key(game):
                """Return an orientation-agnostic key for duplicate detection."""
                date = game.get('date')
                home_id = int(game.get('home_team_id'))
                away_id = int(game.get('away_team_id'))
                min_id, max_id = sorted([home_id, away_id])

                def score_token(val):
                    if isinstance(val, int):
                        return f"{val:02d}"
                    if val is None:
                        return 'NA'
                    try:
                        return f"{int(val):02d}"
                    except Exception:
                        return str(val)

                score_signature = tuple(sorted([
                    score_token(game.get('home_score')),
                    score_token(game.get('away_score'))
                ]))

                status = game.get('status')
                final_inning = game.get('final_inning')
                game_time = game.get('game_time')
                return (date, min_id, max_id, score_signature, status, final_inning, game_time)
            
            # scoreTable í´ë˜ìŠ¤ì˜ í…Œì´ë¸”ë“¤ì—ì„œ ê²½ê¸° ê²°ê³¼ íŒŒì‹±
            score_tables = soup.find_all('table', class_='scoreTable')
            # ë ˆì´ì•„ì›ƒ/ì°¨ë‹¨ ì´ìŠˆë¡œ ë¹„ì–´ ìˆì„ ë•Œ í•œ ë²ˆ ì¬ì‹œë„
            if not score_tables:
                time.sleep(1)
                response = requests.get(url, timeout=20, headers=headers)
                response.raise_for_status()
                soup = BeautifulSoup(response.content, 'html.parser')
                score_tables = soup.find_all('table', class_='scoreTable')
            
            for table in score_tables:
                try:
                    rows = table.find_all('tr')
                    if len(rows) < 3:  # í—¤ë” + 2íŒ€ ìµœì†Œ í•„ìš”
                        continue
                    
                    # íŒ€ëª… ì¶”ì¶œ (ë‘ ë²ˆì§¸, ì„¸ ë²ˆì§¸ í–‰)
                    away_row = rows[1]  # ì²« ë²ˆì§¸ íŒ€ (away)
                    home_row = rows[2]  # ë‘ ë²ˆì§¸ íŒ€ (home)
                    
                    # íŒ€ëª…ì—ì„œ ê³µë°± ì œê±°í•˜ê³  ë§¤í•‘
                    away_team_text = away_row.find('td', class_='team').get_text(strip=True).replace('\xa0', '')
                    home_team_text = home_row.find('td', class_='team').get_text(strip=True).replace('\xa0', '')
                    
                    away_team = self.get_team_info(away_team_text)
                    home_team = self.get_team_info(home_team_text)
                    
                    if not away_team or not home_team:
                        self.logger.warning(f"âš ï¸ Team not found: {away_team_text} vs {home_team_text}")
                        continue
                    
                    # totalScore í´ë˜ìŠ¤ì—ì„œ ì´ì  ì¶”ì¶œ
                    away_score_cell = away_row.find('td', class_='totalScore')
                    home_score_cell = home_row.find('td', class_='totalScore')
                    
                    if not away_score_cell or not home_score_cell:
                        self.logger.warning(f"âš ï¸ Could not find totalScore cells")
                        continue
                    
                    # ì ìˆ˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    away_score_text = away_score_cell.get_text(strip=True)
                    home_score_text = home_score_cell.get_text(strip=True)

                    # ìˆ«ì íŒŒì‹± ìœ í‹¸ (í’€ì™€ì´ë“œ ìˆ«ì í¬í•¨). ì‹¤íŒ¨ ì‹œ None ë°˜í™˜í•˜ì—¬ ìŠ¤í‚µ
                    def convert_jp_number(text: str):
                        if text is None:
                            return None
                        # ì „ê° ìˆ«ìë¥¼ ë°˜ê°ìœ¼ë¡œ ì¹˜í™˜
                        trans = str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789')
                        t = text.translate(trans)
                        # í”í•œ ë¹„ìˆ«ì ê¸°í˜¸ ì œê±° (ëŒ€ì‰¬, ê³µë°±)
                        t = t.replace('\u2014', '-')\
                             .replace('\u2013', '-')\
                             .replace('ï¼', '-')\
                             .replace('â€”', '-')\
                             .strip()
                        # ëª…ë°±í•œ ë¹„ì™„ë£Œ/ì·¨ì†Œ í‘œì‹œ ì²˜ë¦¬: ìˆ«ìê°€ ì—†ìœ¼ë©´ None
                        if not any(ch.isdigit() for ch in t):
                            return None
                        # ìˆ«ìë§Œ ë‚¨ê¸°ê¸° (ì˜ˆ: '10' ê·¸ëŒ€ë¡œ, 'X' ë“± ì œê±°)
                        cleaned = ''.join(ch for ch in t if ch.isdigit())
                        if cleaned == '':
                            return None
                        try:
                            return int(cleaned)
                        except Exception:
                            return None

                    away_score = convert_jp_number(away_score_text)
                    home_score = convert_jp_number(home_score_text)

                    # ê²½ê¸° ìƒíƒœ ì •ë³´ ì¶”ì¶œì„ ë¨¼ì € ìˆ˜í–‰í•´ ì¤‘ë„ ì·¨ì†Œ ë“±ì„ ê°ì§€
                    game_status_info = self.extract_game_status(table)
                    status = game_status_info['status']

                    if status != 'postponed':
                        score_tokens = f"{away_score_text} {home_score_text}"
                        postponed_markers = ['ä¸­æ­¢', 'é›¨å¤©', 'é™é›¨', 'ãƒãƒ¼ã‚²ãƒ¼ãƒ ', 'ãƒãƒ¼ã‚³ãƒ³ãƒ†ã‚¹ãƒˆ', 'æ‰“åˆ‡', 'æ‰“ã¡åˆ‡ã‚Š', 'å»¶æœŸ', 'ã‚µã‚¹ãƒšãƒ³ãƒ‡ãƒƒãƒ‰']
                        if any(marker in score_tokens for marker in postponed_markers):
                            status = 'postponed'
                            game_status_info['status'] = 'postponed'

                    # ì§„í–‰ ì¤‘ì¸ ê²½ê¸°ëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ
                    if status == 'inprogress':
                        self.logger.info(f"â­ï¸ Skipping in-progress game: {away_team['abbr']} vs {home_team['abbr']}")
                        continue

                    if status == 'postponed':
                        away_score = None
                        home_score = None
                    elif away_score is None or home_score is None:
                        self.logger.info(
                            f"â­ï¸  Skipping unparsed/unfinished game: {away_team['abbr']} vs {home_team['abbr']} (away='{away_score_text}', home='{home_score_text}')"
                        )
                        continue

                    # ë¦¬ê·¸ íŒë‹¨: êµë¥˜ì „ í™•ì¸ í›„ ë¶„ë¥˜
                    home_league = home_team['league']
                    away_league = away_team['league']

                    if home_league == away_league:
                        # ê°™ì€ ë¦¬ê·¸ ë‚´ ê²½ê¸°
                        league = home_league
                    else:
                        # êµë¥˜ì „: í™ˆíŒ€ ë¦¬ê·¸ë¡œ ë¶„ë¥˜
                        league = home_league

                    # ì ìˆ˜ê°€ ìˆìœ¼ë©´ì„œ ìƒíƒœê°€ ë¶ˆë¶„ëª…í•  ë•Œë§Œ ì¶”ê°€ í™•ì¸
                    if home_score is not None and away_score is not None and status == 'scheduled':
                        # ë” ì •í™•í•œ ì™„ë£Œ ìƒíƒœ íŒë‹¨
                        status = self.determine_completion_status(table, game_status_info)

                    # ìƒì„¸ ê²½ê¸° ì •ë³´ ìˆ˜ì§‘ (ì™„ë£Œëœ ê²½ê¸°ëŠ” ë” ë§ì€ ì •ë³´ ìˆ˜ì§‘)
                    detailed_info = {}
                    if status == 'completed':
                        detailed_info = self.extract_detailed_game_info(table, away_team, home_team)

                    # ë¬´ìŠ¹ë¶€ íŒì •(ê°•í™”): ì™„ë£Œ && ë™ì  â†’ ë¬´ìŠ¹ë¶€ë¡œ ê°„ì£¼
                    # í‚¤ì›Œë“œ ë³´ê°•(ë¡œê·¸ìš©): å¼•ãåˆ†ã‘/å¼•åˆ†/è¦å®šã«ã‚ˆã‚Šå¼•ãåˆ†ã‘ ãªã©
                    is_draw = False
                    final_inning = None
                    if status == 'completed' and home_score is not None and away_score is not None:
                        innings_home = detailed_info.get('inning_scores_home') or []
                        innings_away = detailed_info.get('inning_scores_away') or []
                        final_inning = max(len(innings_home), len(innings_away)) if (innings_home or innings_away) else None
                        if home_score == away_score:
                            is_draw = True
                            page_text = table.get_text(' ', strip=True)
                            if any(k in page_text for k in ['å¼•ãåˆ†ã‘', 'å¼•åˆ†', 'è¦å®šã«ã‚ˆã‚Šå¼•ãåˆ†ã‘']):
                                self.logger.info("ğŸ¤ Draw detected by keyword")
                            elif final_inning is not None:
                                self.logger.info(f"ğŸ¤ Draw detected by equal score @ {final_inning}å›")

                    winner = None
                    if home_score is not None and away_score is not None:
                        if home_score > away_score:
                            winner = 'home'
                        elif away_score > home_score:
                            winner = 'away'
                        else:
                            winner = 'draw'

                    # ê²½ê¸° ì •ë³´ (í™•ì¥ëœ í•„ë“œ)
                    game = {
                        'date': target_date.strftime('%Y-%m-%d'),
                        'home_team_id': home_team['id'],
                        'home_team_name': home_team['name'],
                        'home_team_abbr': home_team['abbr'],
                        'away_team_id': away_team['id'],
                        'away_team_name': away_team['name'],
                        'away_team_abbr': away_team['abbr'],
                        'home_score': home_score,
                        'away_score': away_score,
                        'league': league,
                        'status': status,
                        'inning': game_status_info.get('inning'),
                        'inning_half': game_status_info.get('inning_half'),
                        'game_time': game_status_info.get('game_time'),
                        'is_draw': is_draw,
                        'winner': winner,
                        # í™•ì¥ í•„ë“œë“¤
                        'stadium': detailed_info.get('stadium'),
                        'game_duration': detailed_info.get('game_duration'),
                        'attendance': detailed_info.get('attendance'),
                        'inning_scores_away': detailed_info.get('inning_scores_away', []),
                        'inning_scores_home': detailed_info.get('inning_scores_home', []),
                        'hits_away': detailed_info.get('hits_away'),
                        'hits_home': detailed_info.get('hits_home'),
                        'errors_away': detailed_info.get('errors_away'),
                        'errors_home': detailed_info.get('errors_home'),
                        'winning_pitcher': detailed_info.get('winning_pitcher'),
                        'losing_pitcher': detailed_info.get('losing_pitcher'),
                        'save_pitcher': detailed_info.get('save_pitcher'),
                        'home_runs': detailed_info.get('home_runs', []),
                        'weather': detailed_info.get('weather'),
                        'temperature': detailed_info.get('temperature'),
                        'final_inning': final_inning
                    }

                    strict_key = (game['date'], game['home_team_id'], game['away_team_id'])
                    symmetric_key = build_symmetric_key(game)

                    existing_game = strict_games.get(strict_key)
                    if existing_game:
                        if self.is_game_data_better(game, existing_game):
                            strict_games[strict_key] = game
                            self.logger.info(f"ğŸ”„ Updated duplicate game with richer data: {away_team['abbr']} vs {home_team['abbr']}")
                        else:
                            self.logger.info(f"â­ï¸ Duplicate game skipped (existing data richer): {away_team['abbr']} vs {home_team['abbr']}")
                        continue

                    mirrored_key = symmetric_map.get(symmetric_key)
                    if mirrored_key is not None:
                        existing_game = strict_games.get(mirrored_key)
                        if existing_game and self.is_game_data_better(game, existing_game):
                            strict_games[mirrored_key] = game
                            self.logger.info(f"ğŸ”„ Replaced mirrored duplicate with richer data: {away_team['abbr']} vs {home_team['abbr']}")
                        else:
                            self.logger.info(f"â­ï¸ Mirrored duplicate skipped: {away_team['abbr']} vs {home_team['abbr']}")
                        continue

                    strict_games[strict_key] = game
                    symmetric_map[symmetric_key] = strict_key

                    score_log = f"{away_score}-{home_score}" if (home_score is not None and away_score is not None) else "--"
                    status_text = f" [{game['status'].upper()}]" if game['status'] != 'completed' else ""
                    self.logger.info(f"âœ… Parsed: {away_team['abbr']} {score_log} {home_team['abbr']}{status_text}")
                    
                except Exception as e:
                    self.logger.warning(f"âš ï¸ Failed to parse table: {e}")
                    continue
            
            games = list(strict_games.values())
            return games
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to crawl from Nikkansports {target_date.strftime('%Y-%m-%d')}: {e}")
            return []
    
    def extract_game_status(self, table):
        """ê²½ê¸° ìƒíƒœ ì •ë³´ ì¶”ì¶œ (ì´ë‹, ì§„í–‰ìƒí™©, ì‹œê°„ ë“±)"""
        status_info = {
            'status': 'scheduled',  # ê¸°ë³¸ê°’: ì˜ˆì •
            'inning': None,
            'inning_half': None,
            'game_time': None
        }
        
        try:
            # 1. H5 íƒœê·¸ì—ì„œ [è©¦åˆä¸­æ­¢] ë˜ëŠ” [è©¦åˆçµ‚äº†] í™•ì¸
            header = table.find_previous_sibling('h5')
            if header:
                header_text = header.get_text()
                if 'è©¦åˆä¸­æ­¢' in header_text:
                    status_info['status'] = 'postponed'
                    return status_info
                draw_keywords = ['å¼•ãåˆ†ã‘', 'å¼•åˆ†', 'è¦å®šã«ã‚ˆã‚Šå¼•ãåˆ†ã‘']
                cold_keywords = ['é™é›¨ã‚³ãƒ¼ãƒ«ãƒ‰', 'ã‚³ãƒ¼ãƒ«ãƒ‰ã‚²ãƒ¼ãƒ ', 'é™é›¨ã‚³ãƒ¼ãƒ«']
                if any(k in header_text for k in draw_keywords + cold_keywords):
                    status_info['status'] = 'completed'
                    inning_match = re.search(r'(?:å»¶é•·)?(\d+)å›', header_text)
                    if inning_match:
                        try:
                            status_info['inning'] = int(inning_match.group(1))
                        except Exception:
                            pass
                    half_match = re.search(r'(è¡¨|è£)', header_text)
                    if half_match:
                        status_info['inning_half'] = 'top' if half_match.group(1) == 'è¡¨' else 'bottom'
                if 'è©¦åˆçµ‚äº†' in header_text:
                    status_info['status'] = 'completed'

            # 2. ê²½ê¸° ì§„í–‰ ìƒíƒœ í™•ì¸ (ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ)
            status_elements = table.find_all(['td', 'th'], class_=['status', 'inning', 'gameStatus'])
            for elem in status_elements:
                text = elem.get_text(strip=True)
                
                # ì§„í–‰ì¤‘ ìƒíƒœ í‚¤ì›Œë“œ ê°œì„  (ë” ì •í™•í•œ íŒ¨í„´ ë§¤ì¹­)
                # "8íšŒë§", "9íšŒí‘œ", "å»¶é•·10å›è£" ë“±ì˜ íŒ¨í„´
                inning_pattern = re.search(r'(?:å»¶é•·)?(\d+)å›([è¡¨è£])', text)
                if inning_pattern:
                    status_info['status'] = 'inprogress' 
                    status_info['inning'] = int(inning_pattern.group(1))
                    status_info['inning_half'] = 'top' if inning_pattern.group(2) == 'è¡¨' else 'bottom'
                    self.logger.info(f"ğŸ”„ In-progress game detected: {status_info['inning']}íšŒ {status_info['inning_half']}")
                    return status_info
                
                # ê¸°íƒ€ ì§„í–‰ì¤‘ í‚¤ì›Œë“œ (ë” êµ¬ì²´ì ìœ¼ë¡œ)
                inprogress_keywords = ['è©¦åˆä¸­', 'ä¸­æ–­ä¸­', 'ãƒ—ãƒ¬ã‚¤ãƒœãƒ¼ãƒ«', 'æ”»æ’ƒä¸­', 'å®ˆå‚™ä¸­']
                if any(keyword in text for keyword in inprogress_keywords):
                    status_info['status'] = 'inprogress'
                    self.logger.info(f"ğŸ”„ In-progress game detected by keyword: {text}")
                    return status_info

                # ì™„ë£Œ ìƒíƒœ í‚¤ì›Œë“œ
                completion_keywords = ['è©¦åˆçµ‚äº†', 'çµ‚äº†', 'ã‚²ãƒ¼ãƒ çµ‚äº†', 'GAME SET', 'FINAL', 'æœ€çµ‚', 'å¼•ãåˆ†ã‘', 'å¼•åˆ†', 'è¦å®šã«ã‚ˆã‚Šå¼•ãåˆ†ã‘']
                if any(keyword in text for keyword in completion_keywords):
                    status_info['status'] = 'completed'
                
                # ì—°ê¸°/ì¤‘ì§€/ë…¸ê²Œì„ ìƒíƒœ í‚¤ì›Œë“œ ê°•í™”
                elif any(keyword in text for keyword in ['é›¨å¤©ä¸­æ­¢', 'ä¸­æ­¢', 'å»¶æœŸ', 'ã‚µã‚¹ãƒšãƒ³ãƒ‡ãƒƒãƒ‰', 'ãƒãƒ¼ã‚²ãƒ¼ãƒ ', 'ãƒãƒ¼ã‚³ãƒ³ãƒ†ã‚¹ãƒˆ', 'æ‰“åˆ‡', 'æ‰“ã¡åˆ‡ã‚Š']):
                    status_info['status'] = 'postponed'

        except Exception as e:
            self.logger.warning(f"âš ï¸ Could not extract game status: {e}")
            
        return status_info
    
    def determine_completion_status(self, table, game_status_info):
        """ì™„ë£Œ/ì·¨ì†Œë¥¼ í…ìŠ¤íŠ¸ í‚¤ì›Œë“œë¡œë§Œ ë³´ìˆ˜ì ìœ¼ë¡œ íŒì •"""
        try:
            if game_status_info.get('status') == 'completed':
                return 'completed'

            text = table.get_text(" ", strip=True)
            if any(k in text for k in ['è©¦åˆçµ‚äº†', 'ã‚²ãƒ¼ãƒ ã‚»ãƒƒãƒˆ', 'å¼•ãåˆ†ã‘', 'ã‚³ãƒ¼ãƒ«ãƒ‰']):
                return 'completed'
            if any(k in text for k in ['é›¨å¤©ä¸­æ­¢', 'ä¸­æ­¢', 'å»¶æœŸ', 'ã‚µã‚¹ãƒšãƒ³ãƒ‡ãƒƒãƒ‰', 'ãƒãƒ¼ã‚²ãƒ¼ãƒ ', 'ãƒãƒ¼ã‚³ãƒ³ãƒ†ã‚¹ãƒˆ', 'æ‰“åˆ‡', 'æ‰“ã¡åˆ‡ã‚Š']):
                return 'postponed'
            return 'scheduled'
        except Exception as e:
            self.logger.warning(f"âš ï¸ Error determining completion status: {e}")
            return 'scheduled'
    
    def extract_detailed_game_info(self, table, away_team, home_team):
        """ì™„ë£Œëœ ê²½ê¸°ì˜ ìƒì„¸ ì •ë³´ ì¶”ì¶œ"""
        detailed_info = {}
        
        try:
            # 1. ì´ë‹ë³„ ë“ì  ì¶”ì¶œ
            score_rows = table.find_all('tr')
            if len(score_rows) >= 3:
                header_row = score_rows[0]
                away_row = score_rows[1]  # ì›ì •íŒ€
                home_row = score_rows[2]  # í™ˆíŒ€
                
                away_innings = []
                home_innings = []

                # Find the index of the total score column ('R' or 'è¨ˆ')
                total_col_idx = -1
                header_cells = header_row.find_all(['th', 'td'])
                for i, cell in enumerate(header_cells):
                    text = cell.get_text(strip=True)
                    if text == 'R' or text == 'è¨ˆ':
                        total_col_idx = i
                        break
                
                away_cells = away_row.find_all('td')
                home_cells = home_row.find_all('td')

                # Slice inning cells based on the location of the 'R' column
                # It starts after the team name (index 0)
                if total_col_idx != -1:
                    inning_cells_away = away_cells[1:total_col_idx]
                    inning_cells_home = home_cells[1:total_col_idx]
                else:
                    # Fallback to old logic if 'R' is not found
                    inning_cells_away = away_cells[1:-3] if len(away_cells) > 4 else away_cells[1:]
                    inning_cells_home = home_cells[1:-3] if len(home_cells) > 4 else home_cells[1:]

                def parse_inning_cell(raw_text):
                    """Convert inning cell text (including walk-off markers like '1X') to an int/None."""
                    t = raw_text.translate(str.maketrans('ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™', '0123456789'))
                    t = t.replace('\u2014', '-').replace('ï¼', '-').replace('â€”', '-')
                    t = t.replace('ï¼¸', 'X').replace('ï½˜', 'X').replace('x', 'X').strip()

                    digits = ''.join(ch for ch in t if ch.isdigit())
                    if digits:
                        return int(digits)
                    if 'X' in t:
                        return None
                    # ì™„ë£Œ ê²½ê¸°ì—ì„œ ë¹„ì–´ ìˆê±°ë‚˜ ê¸°í˜¸ë§Œ ìˆëŠ” ì¹¸ì€ 0ìœ¼ë¡œ ì·¨ê¸‰
                    return 0

                for i, cell in enumerate(inning_cells_away, 1):
                    if i > 15:  # ìµœëŒ€ 15íšŒê¹Œì§€ë§Œ
                        break
                    text = cell.get_text(strip=True)
                    away_innings.append(parse_inning_cell(text))
                
                for i, cell in enumerate(inning_cells_home, 1):
                    if i > 15:  # ìµœëŒ€ 15íšŒê¹Œì§€ë§Œ
                        break
                    text = cell.get_text(strip=True)
                    home_innings.append(parse_inning_cell(text))
                
                detailed_info['inning_scores_away'] = away_innings
                detailed_info['inning_scores_home'] = home_innings
                
                # 2. R(ë“ì ), H(ì•ˆíƒ€), E(ì‹¤ì±…) ì •ë³´ ì¶”ì¶œ
                # ë³´í†µ í…Œì´ë¸”ì˜ ë§ˆì§€ë§‰ 3ê°œ ì»¬ëŸ¼ì´ R, H, E
                try:
                    away_rhe = away_cells[-3:]
                    home_rhe = home_cells[-3:]
                    
                    if len(away_rhe) >= 3:
                        detailed_info['hits_away'] = int(away_rhe[1].get_text(strip=True)) if away_rhe[1].get_text(strip=True).isdigit() else None
                        detailed_info['errors_away'] = int(away_rhe[2].get_text(strip=True)) if away_rhe[2].get_text(strip=True).isdigit() else None
                    
                    if len(home_rhe) >= 3:
                        detailed_info['hits_home'] = int(home_rhe[1].get_text(strip=True)) if home_rhe[1].get_text(strip=True).isdigit() else None
                        detailed_info['errors_home'] = int(home_rhe[2].get_text(strip=True)) if home_rhe[2].get_text(strip=True).isdigit() else None
                        
                except (ValueError, IndexError):
                    pass
            
            # 3. êµ¬ì¥ ì •ë³´ ì¶”ì¶œ (í˜ì´ì§€ì—ì„œ êµ¬ì¥ëª… ì°¾ê¸°)
            stadium_elements = table.find_parent().find_all(text=lambda text: text and any(
                stadium in text for stadium in ['ãƒ‰ãƒ¼ãƒ ', 'çƒå ´', 'ã‚¹ã‚¿ã‚¸ã‚¢ãƒ ', 'ãƒ‘ãƒ¼ã‚¯']
            ))
            if stadium_elements:
                detailed_info['stadium'] = stadium_elements[0].strip()
            else:
                # ê¸°ë³¸ êµ¬ì¥ìœ¼ë¡œ ì¶”ì •
                detailed_info['stadium'] = self.default_stadium_by_abbr.get(home_team['abbr'], 'êµ¬ì¥ë¯¸ì •')
            
            # 4. ì¶”ê°€ ê²½ê¸° ì •ë³´ (ì‹œê°„, ê´€ì¤‘ ë“±)
            info_elements = table.find_parent().find_all(['p', 'div'], class_=['game-info', 'match-info'])
            for elem in info_elements:
                text = elem.get_text()
                
                # ê²½ê¸° ì‹œê°„ ì¶”ì¶œ (ì˜ˆ: "2ì‹œê°„ 35ë¶„")
                time_match = re.search(r'(\d+)æ™‚é–“(\d+)åˆ†', text)
                if time_match:
                    hours = int(time_match.group(1))
                    minutes = int(time_match.group(2))
                    detailed_info['game_duration'] = f"{hours}:{minutes:02d}"
                
                # ê´€ì¤‘ ìˆ˜ ì¶”ì¶œ (ì˜ˆ: "ê´€ì¤‘ 35,000ëª…")
                attendance_match = re.search(r'(\d{1,3}(?:,\d{3})*)', text)
                if attendance_match and 'è¦³å®¢' in text:
                    detailed_info['attendance'] = int(attendance_match.group(1).replace(',', ''))
                
                # ë‚ ì”¨ ì •ë³´
                if 'æ™´' in text:
                    detailed_info['weather'] = 'æ™´ã‚Œ'
                elif 'æ›‡' in text:
                    detailed_info['weather'] = 'æ›‡ã‚Š'
                elif 'é›¨' in text:
                    detailed_info['weather'] = 'é›¨'
                
                # ì˜¨ë„ ì •ë³´
                temp_match = re.search(r'(\d+)åº¦', text)
                if temp_match:
                    detailed_info['temperature'] = int(temp_match.group(1))
            
            self.logger.info(f"ğŸ“Š Collected detailed info: stadium={detailed_info.get('stadium', 'N/A')}, innings={len(detailed_info.get('inning_scores_away', []))}")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Error extracting detailed game info: {e}")
        
        return detailed_info
    
    def validate_game_data(self, game):
        """ê²½ê¸° ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬"""
        required_fields = ['date', 'home_team_id', 'away_team_id', 'home_team_abbr', 'away_team_abbr', 'league']
        
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        for field in required_fields:
            if field not in game or game[field] is None:
                self.logger.warning(f"âš ï¸ Missing required field: {field}")
                return False
        
        # ë‚ ì§œ í˜•ì‹ ê²€ì‚¬
        try:
            from datetime import datetime
            datetime.strptime(game['date'], '%Y-%m-%d')
        except ValueError:
            self.logger.warning(f"âš ï¸ Invalid date format: {game['date']}")
            return False
        
        # íŒ€ ID ê²€ì‚¬ (1-12 ë²”ìœ„)
        if not (1 <= game['home_team_id'] <= 12) or not (1 <= game['away_team_id'] <= 12):
            self.logger.warning(f"âš ï¸ Invalid team IDs: home={game['home_team_id']}, away={game['away_team_id']}")
            return False
        
        # ê°™ì€ íŒ€ ê²½ê¸° ê²€ì‚¬
        if game['home_team_id'] == game['away_team_id']:
            self.logger.warning(f"âš ï¸ Same team playing: {game['home_team_abbr']}")
            return False
        
        # ìŠ¤ì½”ì–´ ê²€ì‚¬ (ìˆìœ¼ë©´ 0 ì´ìƒ)
        if game.get('home_score') is not None:
            if not isinstance(game['home_score'], int) or game['home_score'] < 0:
                self.logger.warning(f"âš ï¸ Invalid home score: {game['home_score']}")
                return False
        
        if game.get('away_score') is not None:
            if not isinstance(game['away_score'], int) or game['away_score'] < 0:
                self.logger.warning(f"âš ï¸ Invalid away score: {game['away_score']}")
                return False
        
        # ë¦¬ê·¸ ê²€ì‚¬
        if game['league'] not in ['Central', 'Pacific']:
            self.logger.warning(f"âš ï¸ Invalid league: {game['league']}")
            return False
        
        return True
    
    def is_game_data_better(self, new_game, existing_game):
        """ìƒˆ ê²Œì„ ë°ì´í„°ê°€ ê¸°ì¡´ ë°ì´í„°ë³´ë‹¤ ë” ì™„ì „í•œì§€ íŒë‹¨"""
        # 0) ê¸°ì¡´ ë°ì´í„°ê°€ ëª…ë°±íˆ ì˜ëª»ëœ ê²½ìš°(ì•½ì–´/ë¦¬ê·¸) ìƒˆ ë°ì´í„° ìš°ì„ 
        def is_valid_game(g):
            return (
                isinstance(g.get('home_team_abbr'), str) and g['home_team_abbr'] in self.valid_abbrs and
                isinstance(g.get('away_team_abbr'), str) and g['away_team_abbr'] in self.valid_abbrs and
                g.get('league') in self.valid_leagues
            )

        existing_valid = is_valid_game(existing_game)
        new_valid = is_valid_game(new_game)
        if new_valid and not existing_valid:
            return True
        if existing_valid and not new_valid:
            return False

        # 1. ì™„ë£Œëœ ê²½ê¸°ê°€ ë¯¸ì™„ë£Œ ê²½ê¸°ë³´ë‹¤ ìš°ì„ 
        new_status = new_game.get('status', 'scheduled')
        existing_status = existing_game.get('status', 'scheduled')
        
        if new_status == 'completed' and existing_status != 'completed':
            return True
        elif existing_status == 'completed' and new_status != 'completed':
            return False
        
        # 2. ìŠ¤ì½”ì–´ê°€ ìˆëŠ” ê²½ê¸°ê°€ ì—†ëŠ” ê²½ê¸°ë³´ë‹¤ ìš°ì„ 
        new_has_scores = (new_game.get('home_score') is not None and 
                         new_game.get('away_score') is not None)
        existing_has_scores = (existing_game.get('home_score') is not None and 
                              existing_game.get('away_score') is not None)
        
        if new_has_scores and not existing_has_scores:
            return True
        elif existing_has_scores and not new_has_scores:
            return False
        
        # 3. ì´ë‹ ì •ë³´ê°€ ë” ë§ì€ ë°ì´í„°ë¥¼ ìš°ì„ 
        new_innings_len = len(new_game.get('inning_scores_home') or [])
        existing_innings_len = len(existing_game.get('inning_scores_home') or [])
        if new_innings_len > existing_innings_len:
            return True
        if existing_innings_len > new_innings_len:
            return False

        # 4. ë” ë§ì€ ì •ë³´ê°€ ìˆëŠ” ê²½ê¸° ìš°ì„  (ê¸°ì¡´ ë¡œì§)
        info_keys = [
            'inning', 'game_time', 'hits_home', 'hits_away', 'errors_home', 'errors_away',
            'stadium', 'game_duration', 'attendance', 'weather'
        ]
        new_info_count = sum(1 for key in info_keys if new_game.get(key) is not None)
        existing_info_count = sum(1 for key in info_keys if existing_game.get(key) is not None)
        
        return new_info_count > existing_info_count
    
    def save_games_to_txt(self, games, filename="games_raw.txt"):
        """ê²½ê¸° ê²°ê³¼ë¥¼ TXT íŒŒì¼ë¡œ ì €ì¥ - ë‚ ì§œë³„ ê·¸ë£¹í™” í˜•íƒœ
        upcoming_games_raw.txtì˜ ê²½ìš°, êµ¬ì¥/ê²½ê¸°ì‹œê°„ í•„ë“œë¥¼ ëì— ì¶”ê°€í•˜ê³  ì „ì²´ íŒŒì¼ì„ ì¬ì‘ì„±í•©ë‹ˆë‹¤.
        """
        if not games:
            return
        
        file_path = self.data_dir / filename
        is_upcoming = (filename == "upcoming_games_raw.txt")
        
        # upcomingë„ ìƒˆë¡œìš´ ë‚ ì§œë³„ ê·¸ë£¹í™” í˜•ì‹ìœ¼ë¡œ ì €ì¥
        if is_upcoming:
            self.save_upcoming_games_grouped_by_date(games, file_path)
            return

        # games_raw.txtëŠ” ìƒˆë¡œìš´ ë‚ ì§œë³„ ê·¸ë£¹í™” í˜•ì‹ìœ¼ë¡œ ì €ì¥
        self.save_games_grouped_by_date(games, file_path)
        
    def save_games_grouped_by_date(self, new_games, file_path):
        """ê²½ê¸°ë¥¼ ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”í•´ì„œ ì˜ˆì˜ê²Œ ì €ì¥"""
        # ê¸°ì¡´ ë°ì´í„° ì½ê¸° (ê¸°ì¡´ì´ íŒŒì´í”„ í˜•ì‹ì´ë©´ íŒŒì‹±)
        existing_games = {}
        
        if file_path.exists():
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                lines = content.split('\n')
                # íŒŒì´í”„ í˜•ì‹ ì—¬ë¶€ëŠ” 'ì£¼ì„ì´ ì•„ë‹Œ' ë¼ì¸ì—ì„œ íŒë‹¨ (ë©”íƒ€ ì£¼ì„ì˜ | ë¬´ì‹œ)
                pipe_mode = any(('|' in ln) and (not ln.strip().startswith('#')) for ln in lines)
                if pipe_mode:
                    # êµ¬(íŒŒì´í”„) í˜•ì‹ íŒŒì‹±
                    for line in lines:
                        if line.startswith('#') or not line.strip():
                            continue
                        parts = line.strip().split('|')
                        if len(parts) >= 12:
                            game_data = {
                                'date': parts[0],
                                'home_team_id': int(parts[1]),
                                'home_team_abbr': parts[2],
                                'home_team_name': parts[3],
                                'away_team_id': int(parts[4]),
                                'away_team_abbr': parts[5],
                                'away_team_name': parts[6],
                                'home_score': None if parts[7] == 'NULL' else int(parts[7]),
                                'away_score': None if parts[8] == 'NULL' else int(parts[8]),
                                'league': parts[9],
                                'status': parts[10],
                                'is_draw': parts[11] == '1'
                            }
                            game_key = (parts[0], parts[1], parts[4])
                            existing_games[game_key] = game_data
                else:
                    # ìƒˆ(ê°€ë…) í˜•ì‹ íŒŒì‹± (ë‚ ì§œë³„ ê·¸ë£¹í™”)
                    current_date = None
                    i = 0
                    while i < len(lines):
                        line = lines[i].strip()
                        if line.startswith('# 202'):
                            current_date = line[2:]
                            i += 1
                            continue
                        if current_date and line and not line.startswith('#'):
                            game_match = re.match(r'^(\w+)\s+((\d+)-(\d+)|vs)\s+(\w+)\s+\((\w+)\)(.*)$', line)
                            if game_match and i + 1 < len(lines):
                                meta_line = lines[i + 1]
                                meta_match = re.match(r'^#\s*(\d+)\|(\d+)\|([^|]+)\|([^|]+)$', meta_line)
                                if meta_match:
                                    gm = game_match.groups()
                                    away_abbr = gm[0]
                                    score_part = gm[1]
                                    away_score_str = gm[2]
                                    home_score_str = gm[3]
                                    home_abbr = gm[4]
                                    league = gm[5]
                                    status_info = gm[6] if len(gm) > 6 else ''

                                    away_id, home_id, away_name, home_name = meta_match.groups()
                                    away_id_i = int(away_id)
                                    home_id_i = int(home_id)

                                    # Repair invalid abbr/league using IDs
                                    if home_abbr not in self.valid_abbrs and home_id_i in self.id_to_team:
                                        home_abbr = self.id_to_team[home_id_i]['abbr']
                                    if away_abbr not in self.valid_abbrs and away_id_i in self.id_to_team:
                                        away_abbr = self.id_to_team[away_id_i]['abbr']
                                    if league not in self.valid_leagues and home_id_i in self.id_to_team:
                                        league = self.id_to_team[home_id_i]['league']

                                    game_data = {
                                        'date': current_date,
                                        'home_team_id': home_id_i,
                                        'home_team_abbr': home_abbr,
                                        'home_team_name': home_name,
                                        'away_team_id': away_id_i,
                                        'away_team_abbr': away_abbr,
                                        'away_team_name': away_name,
                                        'home_score': int(home_score_str) if home_score_str else None,
                                        'away_score': int(away_score_str) if away_score_str else None,
                                        'league': league,
                                        'status': 'completed' if score_part != 'vs' else 'scheduled',
                                        'is_draw': '[DRAW]' in (status_info or '')
                                    }
                                    game_key = (current_date, home_id, away_id)
                                    existing_games[game_key] = game_data
                                    i += 2
                                    continue
                        i += 1
            except Exception as e:
                self.logger.warning(f"Failed to read existing file: {e}")
        
        # ìƒˆ ê²Œì„ ë°ì´í„° ê²€ì¦ ë° ì²˜ë¦¬
        validated_games = []
        for game in new_games:
            if self.validate_game_data(game):
                validated_games.append(game)
            else:
                self.logger.warning(f"âš ï¸ Invalid game data skipped: {game.get('away_team_abbr', 'UNK')} vs {game.get('home_team_abbr', 'UNK')} on {game.get('date', 'UNK')}")
        
        # REWRITE_DATES ëª¨ë“œ: ìƒˆ ê²Œì„ì´ í¬í•¨ëœ ë‚ ì§œì˜ ê¸°ì¡´ ë ˆì½”ë“œë¥¼ ëª¨ë‘ ì œê±°
        try:
            rewrite_flag = os.environ.get('REWRITE_DATES', '').upper()
        except Exception:
            rewrite_flag = ''
        target_dates = {g['date'] for g in validated_games}
        if rewrite_flag in ('AUTO', 'ALL', '1', 'TRUE', 'YES') and target_dates:
            existing_games = {k: v for k, v in existing_games.items() if v.get('date') not in target_dates}

        # ì¤‘ë³µ ì œê±° ë° ë³‘í•©
        for game in validated_games:
            game_key = (game['date'], str(game['home_team_id']), str(game['away_team_id']))
            
            # ì¤‘ë³µ í™•ì¸ ë° ë” ì™„ì „í•œ ë°ì´í„° ì„ íƒ
            if game_key in existing_games:
                existing = existing_games[game_key]
                # ìƒˆ ë°ì´í„°ê°€ ë” ì™„ì „í•˜ë©´ êµì²´
                if self.is_game_data_better(game, existing):
                    existing_games[game_key] = game
                    self.logger.info(f"ğŸ”„ Updated game: {game['away_team_abbr']} vs {game['home_team_abbr']} on {game['date']}")
            else:
                existing_games[game_key] = game
        
        # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
        games_by_date = {}
        for game in existing_games.values():
            date = game['date']
            if date not in games_by_date:
                games_by_date[date] = []
            games_by_date[date].append(game)
        
        # ìƒˆ í˜•ì‹ìœ¼ë¡œ íŒŒì¼ ì“°ê¸°
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("# NPB GAMES DATA\n")
            f.write(f"# UPDATED: {datetime.now().isoformat()}\n")
            f.write("# FORMAT: Date-grouped games with readable format\n")
            f.write("#\n")
            
            # ë‚ ì§œìˆœ ì •ë ¬
            for date in sorted(games_by_date.keys()):
                f.write(f"\n# {date}\n")
                
                for game in games_by_date[date]:
                    # íŒ€ ë ˆì´ë¸”(ì¼ë³¸ì–´ ì§§ì€ í‘œê¸°) ì¤€ë¹„
                    away_label = self.abbr_to_ja_short.get(game['away_team_abbr'], (game.get('away_team_name') or '')[:2] or game['away_team_abbr'])
                    home_label = self.abbr_to_ja_short.get(game['home_team_abbr'], (game.get('home_team_name') or '')[:2] or game['home_team_abbr'])
                    # ìŠ¤ì½”ì–´ í‘œì‹œ
                    if game['home_score'] is not None and game['away_score'] is not None:
                        score = f"{game['away_score']}-{game['home_score']}"
                    else:
                        score = "vs"
                    
                    # ë¬´ìŠ¹ë¶€ í‘œì‹œ
                    draw_mark = " [DRAW]" if game.get('is_draw', False) else ""
                    
                    # ìƒíƒœ í‘œì‹œ 
                    status_mark = ""
                    if game.get('status') == 'scheduled':
                        status_mark = " [SCHEDULED]"
                    elif game.get('status') == 'postponed':
                        status_mark = " [POSTPONED]"
                    
                    # ê²Œì„ ë¼ì¸ ì‘ì„±: æ—¥æœ¬ãƒãƒ  0-0 é˜ªç¥ (League) [DRAW] @ Stadium 
                    game_line = f"{away_label} {score} {home_label} ({game['league']}){draw_mark}{status_mark}"
                    
                    stadium = game.get('stadium') or self.default_stadium_by_abbr.get(game.get('home_team_abbr'), '')
                    info_tokens = []
                    if stadium:
                        info_tokens.append(f"@ {stadium}")
                    # ê²½ê¸° ì‹œê°„/ì†Œìš” ì‹œê°„/ê´€ì¤‘ ì •ë³´ëŠ” ì¡´ì¬ ì‹œ ë§ë¶™ì„
                    if game.get('game_time') and game.get('status') != 'completed':
                        info_tokens.append(game['game_time'])
                    if game.get('game_duration'):
                        info_tokens.append(f"â±ï¸{game['game_duration']}")
                    if game.get('attendance'):
                        try:
                            info_tokens.append(f"ğŸ‘¥{int(game['attendance']):,}ëª…")
                        except Exception:
                            info_tokens.append(f"ğŸ‘¥{game['attendance']}")
                    if info_tokens:
                        game_line += " " + " ".join(info_tokens)
                    
                    f.write(f"{game_line}\n")
                    
                    inning_line = None
                    away_innings = game.get('inning_scores_away') or []
                    home_innings = game.get('inning_scores_home') or []
                    if away_innings or home_innings:
                        max_innings = max(len(away_innings), len(home_innings))
                        if max_innings > 0:
                            parts = []
                            for idx in range(max_innings):
                                away_score = away_innings[idx] if idx < len(away_innings) else "X"
                                home_score = home_innings[idx] if idx < len(home_innings) else "X"
                                if away_score is None:
                                    away_score = "X"
                                if home_score is None:
                                    home_score = "X"
                                parts.append(f"{idx + 1}íšŒ({away_score}-{home_score})")
                            inning_line = "ì´ë‹ë³„: " + " ".join(parts)
                    
                    if inning_line:
                        f.write(f"# ğŸ“Š {inning_line}\n")
        
        total_games = sum(len(games) for games in games_by_date.values())
        self.logger.info(f"ğŸ“„ Saved {total_games} games grouped by {len(games_by_date)} dates to {file_path}")
    
    def save_upcoming_games_grouped_by_date(self, games, file_path):
        """ì˜ˆì • ê²½ê¸°ë¥¼ ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”í•´ì„œ ì €ì¥ (êµ¬ì¥/ì‹œê°„ ì •ë³´ í¬í•¨)"""
        # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
        games_by_date = {}
        for game in games:
            date = game['date']
            if date not in games_by_date:
                games_by_date[date] = []
            games_by_date[date].append(game)
        
        # ìƒˆ í˜•ì‹ìœ¼ë¡œ íŒŒì¼ ì“°ê¸°
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write("# NPB SCHEDULED GAMES DATA\n")
            f.write(f"# UPDATED: {datetime.now().isoformat()}\n")
            f.write("# FORMAT: Date-grouped scheduled games with venue and time info\n")
            f.write("#\n")
            
            # ë‚ ì§œìˆœ ì •ë ¬
            for date in sorted(games_by_date.keys()):
                f.write(f"\n# {date}\n")
                
                for game in games_by_date[date]:
                    # íŒ€ ë ˆì´ë¸”(ì¼ë³¸ì–´ ì§§ì€ í‘œê¸°) ì¤€ë¹„
                    away_label = self.abbr_to_ja_short.get(game['away_team_abbr'], (game.get('away_team_name') or '')[:2] or game['away_team_abbr'])
                    home_label = self.abbr_to_ja_short.get(game['home_team_abbr'], (game.get('home_team_name') or '')[:2] or game['home_team_abbr'])
                    # êµ¬ì¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    stadium = game.get('stadium')
                    if not stadium:
                        abbr = game.get('home_team_abbr')
                        stadium = self.default_stadium_by_abbr.get(abbr, 'êµ¬ì¥ë¯¸ì •')
                    
                    # ê²½ê¸° ì‹œê°„
                    game_time = game.get('game_time', 'ì‹œê°„ë¯¸ì •')
                    
                    # ì˜ˆì • ê²½ê¸° ë¼ì¸: ãƒ¤ã‚¯ãƒ«ãƒˆ vs å·¨äºº (Central) [SCHEDULED] @ æ˜æ²»ç¥å®®é‡çƒå ´ 18:00
                    game_line = f"{away_label} vs {home_label} ({game['league']}) [SCHEDULED] @ {stadium} {game_time}"
                    
                    # ë©”íƒ€ë°ì´í„° ì£¼ì„ - ì–´ì›¨ì´íŒ€ì´ ë¨¼ì €
                    meta_line = f"# {game['away_team_id']}|{game['home_team_id']}|{game['away_team_name']}|{game['home_team_name']}"
                    
                    f.write(f"{game_line}\n")
                    f.write(f"{meta_line}\n")
        
        total_games = sum(len(games) for games in games_by_date.values())
        self.logger.info(f"ğŸ“„ Saved {total_games} scheduled games grouped by {len(games_by_date)} dates to {file_path}")
    
    def save_teams_to_txt(self):
        """íŒ€ ì •ë³´ë¥¼ TXT íŒŒì¼ë¡œ ì €ì¥"""
        # Skip writing unless explicitly enabled
        try:
            if str(os.environ.get('WRITE_TEAMS_TXT', '')).lower() not in ('1','true','yes'):
                self.logger.info("â­ï¸ Skipping teams_raw.txt write (WRITE_TEAMS_TXT not set)")
                return
        except Exception:
            return
        file_path = self.data_dir / "teams_raw.txt"
        
        lines = []
        lines.append("# NPB_TEAMS_DATA")
        lines.append(f"# UPDATED: {datetime.now().isoformat()}")
        lines.append("# FORMAT: TEAM_ID|TEAM_ABBR|TEAM_NAME|LEAGUE")
        
        # ì¤‘ë³µ ì œê±°: ê³ ì • 12íŒ€ë§Œ ì¶œë ¥ (id ì˜¤ë¦„ì°¨ìˆœ)
        canonical = {
            1: {'id':1,'abbr':'YOG','name':'èª­å£²ã‚¸ãƒ£ã‚¤ã‚¢ãƒ³ãƒ„','league':'Central'},
            2: {'id':2,'abbr':'HAN','name':'é˜ªç¥ã‚¿ã‚¤ã‚¬ãƒ¼ã‚¹','league':'Central'},
            3: {'id':3,'abbr':'YDB','name':'æ¨ªæµœDeNAãƒ™ã‚¤ã‚¹ã‚¿ãƒ¼ã‚º','league':'Central'},
            4: {'id':4,'abbr':'HIR','name':'åºƒå³¶æ±æ´‹ã‚«ãƒ¼ãƒ—','league':'Central'},
            5: {'id':5,'abbr':'CHU','name':'ä¸­æ—¥ãƒ‰ãƒ©ã‚´ãƒ³ã‚º','league':'Central'},
            6: {'id':6,'abbr':'YAK','name':'æ±äº¬ãƒ¤ã‚¯ãƒ«ãƒˆã‚¹ãƒ¯ãƒ­ãƒ¼ã‚º','league':'Central'},
            7: {'id':7,'abbr':'SOF','name':'ç¦å²¡ã‚½ãƒ•ãƒˆãƒãƒ³ã‚¯ãƒ›ãƒ¼ã‚¯ã‚¹','league':'Pacific'},
            8: {'id':8,'abbr':'LOT','name':'åƒè‘‰ãƒ­ãƒƒãƒ†ãƒãƒªãƒ¼ãƒ³ã‚º','league':'Pacific'},
            9: {'id':9,'abbr':'RAK','name':'æ±åŒ—æ¥½å¤©ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ã‚¤ãƒ¼ã‚°ãƒ«ã‚¹','league':'Pacific'},
            10:{'id':10,'abbr':'ORI','name':'ã‚ªãƒªãƒƒã‚¯ã‚¹ãƒãƒ•ã‚¡ãƒ­ãƒ¼ã‚º','league':'Pacific'},
            11:{'id':11,'abbr':'SEI','name':'åŸ¼ç‰è¥¿æ­¦ãƒ©ã‚¤ã‚ªãƒ³ã‚º','league':'Pacific'},
            12:{'id':12,'abbr':'NIP','name':'åŒ—æµ·é“æ—¥æœ¬ãƒãƒ ãƒ•ã‚¡ã‚¤ã‚¿ãƒ¼ã‚º','league':'Pacific'},
        }
        for team_id in sorted(canonical.keys()):
            info = canonical[team_id]
            line = "|".join([
                str(info['id']),
                info['abbr'],
                info['name'],
                info['league']
            ])
            lines.append(line)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        self.logger.info(f"ğŸ“„ Saved teams to {file_path}")
    
    def crawl_full_season(self, start_date="2025-03-28"):
        """NPB ì‹œì¦Œ ì „ì²´ í¬ë¡¤ë§ (3ì›” 28ì¼ë¶€í„°)"""
        self.logger.info(f"ğŸš€ Starting full NPB season crawl from {start_date}...")
        
        if not CRAWLING_ENABLED:
            self.logger.error("âŒ Web crawling dependencies (requests, beautifulsoup4) are not installed. Cannot crawl.")
            self.logger.error("Please install them using: pip install -r crawler/requirements.txt")
            return 0 # Indicate failure
        
        all_games = []
        start = datetime.strptime(start_date, "%Y-%m-%d")
        today = datetime.now()
        
        # ë‹¹ì¼ ê²½ê¸°ë„ í¬í•¨ (ì™„ë£Œëœ ê²½ê¸°ëŠ” ìˆ˜ì§‘)
        end_date = today
        current_date = start
        total_days = (end_date - start).days + 1
        
        self.logger.info(f"ğŸ“… Crawling {total_days} days from {start_date} to {today.strftime('%Y-%m-%d')}")
        
        day_count = 0
        while current_date <= end_date:
            day_count += 1
            games = self.crawl_date(current_date)
            
            if games:
                all_games.extend(games)
                self.logger.info(f"ğŸ“… {current_date.strftime('%Y-%m-%d')}: {len(games)} games")
            else:
                # ê²½ê¸° ì—†ëŠ” ë‚  (íœ´ì‹ì¼)
                pass
            
            # ì§„í–‰ë¥  í‘œì‹œ
            if day_count % 10 == 0 or day_count == total_days:
                progress = (day_count / total_days) * 100
                self.logger.info(f"ğŸ”„ Progress: {day_count}/{total_days} days ({progress:.1f}%)")
            
            current_date += timedelta(days=1)
            
            # ìš”ì²­ ê°„ê²© (ì„œë²„ ë¶€í•˜ ë°©ì§€) â€” ì†ë„ í–¥ìƒ
            time.sleep(0.1)
        
        # ê²½ê¸° ê²°ê³¼ ì €ì¥
        if all_games:
            self.save_games_to_txt(all_games)
        
        # íŒ€ ì •ë³´ ì €ì¥
        self.save_teams_to_txt()
        
        self.logger.info(f"ğŸ† **FULL SEASON CRAWL SUMMARY**")
        self.logger.info(f"Total games: {len(all_games)}")
        self.logger.info(f"Draws: {sum(1 for g in all_games if g['is_draw'])}")
        self.logger.info(f"Period: {start_date} to {today.strftime('%Y-%m-%d')}")
        
        # ì‹œì¦Œ í†µê³„
        if all_games:
            teams_count = {}
            for game in all_games:
                home_team = game['home_team_abbr']
                away_team = game['away_team_abbr']
                teams_count[home_team] = teams_count.get(home_team, 0) + 1
                teams_count[away_team] = teams_count.get(away_team, 0) + 1
            
            self.logger.info("ğŸ“Š **TEAM GAMES COUNT**:")
            for team, count in sorted(teams_count.items()):
                self.logger.info(f"  {team}: {count} games")
        
        return len(all_games)

    def crawl_multiple_days(self, days=7):
        """ì—¬ëŸ¬ ë‚ ì§œ í¬ë¡¤ë§"""
        self.logger.info(f"ğŸš€ Starting simple crawl for last {days} days...")
        
        if not CRAWLING_ENABLED:
            self.logger.error("âŒ Web crawling dependencies (requests, beautifulsoup4) are not installed. Cannot crawl.")
            self.logger.error("Please install them using: pip install -r crawler/requirements.txt")
            return 0 # Indicate failure
        
        all_games = []
        today = datetime.now()
        
        for i in range(0, days):  # ì˜¤ëŠ˜ë¶€í„° ì‹œì‘  
            target_date = today - timedelta(days=i)
            games = self.crawl_date(target_date)
            all_games.extend(games)
            
            # ìš”ì²­ ê°„ê²© â€” ì†ë„ í–¥ìƒ
            if i < days:
                time.sleep(0.1)
        
        # ê²½ê¸° ê²°ê³¼ ì €ì¥
        if all_games:
            self.save_games_to_txt(all_games)
        
        # íŒ€ ì •ë³´ ì €ì¥
        self.save_teams_to_txt()
        
        self.logger.info(f"ğŸ† **SIMPLE CRAWL SUMMARY**")
        self.logger.info(f"Total games: {len(all_games)}")
        self.logger.info(f"Draws: {sum(1 for g in all_games if g['is_draw'])}")
        
        return len(all_games)



    def crawl_upcoming_games(self, days_ahead=3):
        """ì˜ˆì • ê²½ê¸° í¬ë¡¤ë§ (NPB ê³µì‹ ì‚¬ì´íŠ¸ì—ì„œ)"""
        if not CRAWLING_ENABLED:
            return []
            
        self.logger.info(f"ğŸ” Crawling upcoming games for next {days_ahead} days...")
        
        all_upcoming_games = []
        today = datetime.now()
        
        for i in range(days_ahead):
            target_date = today + timedelta(days=i)
            games = self.crawl_upcoming_date(target_date)
            all_upcoming_games.extend(games)
            
            # ìš”ì²­ ê°„ê²©
            if i < days_ahead - 1:
                time.sleep(1)
        
        if all_upcoming_games:
            self.save_games_to_txt(all_upcoming_games, "upcoming_games_raw.txt")
        
        self.logger.info(f"ğŸ“… Found {len(all_upcoming_games)} upcoming games")
        return all_upcoming_games

    def crawl_game_detail(self, target_date):
        """íŠ¹ì • ë‚ ì§œì˜ ê²½ê¸° ìƒì„¸ ì •ë³´ í¬ë¡¤ë§ (NPB ê³µì‹ ì‚¬ì´íŠ¸)"""
        if not CRAWLING_ENABLED:
            return []
            
        # NPB ê³µì‹ ìŠ¤ì½”ì–´ í˜ì´ì§€ í˜•ì‹: https://npb.jp/scores/2025/0908/
        date_str = target_date.strftime("%m%d")
        year = target_date.year
        url = f"https://npb.jp/scores/{year}/{date_str}/"
        
        self.logger.info(f"ğŸ” Checking game details: {target_date.strftime('%Y-%m-%d')}")
        
        try:
            soup = self.fetch_soup(url, wait_css='table') or BeautifulSoup(b'', 'html.parser')
            games = []
            
            # NPB ìŠ¤ì½”ì–´ í˜ì´ì§€ì—ì„œ ê° ê²½ê¸° ë§í¬ ì°¾ê¸°
            game_links = soup.find_all('a', href=lambda x: x and '/scores/' in x and target_date.strftime('%Y') in x)
            
            for link in game_links:
                href = link.get('href')
                if href and 'detail' not in href:  # ìƒì„¸ í˜ì´ì§€ê°€ ì•„ë‹Œ ë©”ì¸ ê²½ê¸° ë§í¬ë§Œ
                    full_url = f"https://npb.jp{href}" if href.startswith('/') else href
                    
                    # ê° ê²½ê¸°ì˜ ìƒì„¸ ì •ë³´ í¬ë¡¤ë§
                    game_detail = self.crawl_single_game(full_url, target_date)
                    if game_detail:
                        games.append(game_detail)
                    
                    # ìš”ì²­ ê°„ê²©
                    time.sleep(0.5)
            
            return games
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to crawl games for {target_date.strftime('%Y-%m-%d')}: {e}")
            return []

    def crawl_single_game(self, game_url, target_date):
        """ë‹¨ì¼ ê²½ê¸°ì˜ ìƒì„¸ ì •ë³´ í¬ë¡¤ë§"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0 Safari/537.36'
            }
            soup = self.fetch_soup(game_url, wait_css='table')
            
            # ê²½ê¸° ì •ë³´ ì¶”ì¶œ
            game_info = {
                'date': target_date.strftime('%Y-%m-%d'),
                'status': 'scheduled',  # ê¸°ë³¸ê°’ì„ scheduledë¡œ ì„¤ì •
                'inning': None,
                'inning_half': None,
                'inning_scores': {'away': [], 'home': []},
                'current_situation': {}
            }
            
            # 1. íŒ€ ì •ë³´ ë° ìµœì¢… ìŠ¤ì½”ì–´ ì¶”ì¶œ
            score_table = soup.find('table', class_='score-table')
            if score_table:
                rows = score_table.find_all('tr')
                if len(rows) >= 3:  # í—¤ë” + away + home
                    away_row = rows[1]
                    home_row = rows[2]
                    
                    # íŒ€ëª… ì¶”ì¶œ
                    away_team_cell = away_row.find('td', class_='team')
                    home_team_cell = home_row.find('td', class_='team')
                    
                    if away_team_cell and home_team_cell:
                        away_team_text = away_team_cell.get_text(strip=True)
                        home_team_text = home_team_cell.get_text(strip=True)
                        
                        away_team = self.get_team_info(away_team_text)
                        home_team = self.get_team_info(home_team_text)
                        
                        if away_team and home_team:
                            game_info['away_team_id'] = away_team['id']
                            game_info['away_team_abbr'] = away_team['abbr']
                            game_info['away_team_name'] = away_team['name']
                            game_info['home_team_id'] = home_team['id']
                            game_info['home_team_abbr'] = home_team['abbr']
                            game_info['home_team_name'] = home_team['name']
                            # ë¦¬ê·¸ íŒë‹¨: êµë¥˜ì „ í™•ì¸ í›„ ë¶„ë¥˜
                            home_league = home_team['league']
                            away_league = away_team['league']
                            
                            if home_league == away_league:
                                # ê°™ì€ ë¦¬ê·¸ ë‚´ ê²½ê¸°
                                game_info['league'] = home_league
                            else:
                                # êµë¥˜ì „: í™ˆíŒ€ ë¦¬ê·¸ë¡œ ë¶„ë¥˜
                                game_info['league'] = home_league
                            
                            # ìµœì¢… ìŠ¤ì½”ì–´ ì¶”ì¶œ
                            away_total = away_row.find('td', class_='total')
                            home_total = home_row.find('td', class_='total')
                            
                            if away_total and home_total:
                                away_score_text = away_total.get_text(strip=True)
                                home_score_text = home_total.get_text(strip=True)
                                
                                # ìŠ¤ì½”ì–´ ë°ì´í„°ëŠ” í•­ìƒ ìˆ˜ì§‘ (ì§„í–‰ì¤‘ì´ë“  ì™„ë£Œë“ )
                                try:
                                    game_info['away_score'] = int(away_score_text)
                                    game_info['home_score'] = int(home_score_text)
                                    game_info['is_draw'] = game_info['away_score'] == game_info['home_score']
                                    game_info['winner'] = 'home' if game_info['home_score'] > game_info['away_score'] else ('away' if game_info['away_score'] > game_info['home_score'] else 'draw')
                                except ValueError:
                                    self.logger.warning(f"âš ï¸ Could not parse scores: away='{away_score_text}', home='{home_score_text}'")
                                    return None
                            
                            # ì´ë‹ë³„ ìŠ¤ì½”ì–´ ì¶”ì¶œ
                            inning_cells_away = away_row.find_all('td', class_='inning')
                            inning_cells_home = home_row.find_all('td', class_='inning')
                            
                            for cell in inning_cells_away:
                                score_text = cell.get_text(strip=True)
                                if score_text.isdigit():
                                    game_info['inning_scores']['away'].append(int(score_text))
                                elif score_text == 'X':
                                    game_info['inning_scores']['away'].append(None)  # í•˜ìœ„íŒ€ 9íšŒë§ì€ X
                            
                            for cell in inning_cells_home:
                                score_text = cell.get_text(strip=True)
                                if score_text.isdigit():
                                    game_info['inning_scores']['home'].append(int(score_text))
                                elif score_text == 'X':
                                    game_info['inning_scores']['home'].append(None)
            
            # 2. ê²½ê¸° ìƒíƒœ ì •ë³´ ì¶”ì¶œ
            status_section = soup.find('div', class_=['game-status'])
            if status_section:
                status_text = status_section.get_text(strip=True)

                # ê²½ê¸° ì™„ë£Œ ìƒíƒœë§Œ í™•ì¸ (ì§„í–‰ì¤‘ì´ë©´ ìƒíƒœ ë³€ê²½ ì•ˆí•¨)
                completion_keywords = ['è©¦åˆçµ‚äº†', 'çµ‚äº†', 'ã‚²ãƒ¼ãƒ çµ‚äº†', 'GAME SET', 'FINAL', 'æœ€çµ‚', 'çµæœ']
                if any(keyword in status_text for keyword in completion_keywords):
                    game_info['status'] = 'completed'
                elif any(keyword in status_text for keyword in ['å»¶æœŸ', 'ä¸­æ­¢', 'é›¨å¤©ä¸­æ­¢']):
                    game_info['status'] = 'postponed'
                # ì§„í–‰ì¤‘ì´ê±°ë‚˜ ê¸°íƒ€ ìƒíƒœë©´ ê¸°ë³¸ê°’(scheduled) ìœ ì§€
            
            # 3. ì¶”ê°€ ê²Œì„ ì‹œê°„ ì •ë³´
            game_time_elem = soup.find(['span', 'div'], class_=['game-time', 'start-time'])
            if game_time_elem:
                game_info['game_time'] = game_time_elem.get_text(strip=True)
            
            return game_info
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ Failed to crawl single game: {game_url} - {e}")
            return None

    def crawl_upcoming_date(self, target_date):
        """íŠ¹ì • ë‚ ì§œì˜ ì˜ˆì • ê²½ê¸° í¬ë¡¤ë§ (NPB ê³µì‹ ì‚¬ì´íŠ¸)"""
        if not CRAWLING_ENABLED:
            return []
            
        # NPB ê³µì‹ ì‚¬ì´íŠ¸ URL í˜•ì‹ (ì¼ë³¸ì–´)
        # https://npb.jp/bis/2025/calendar/index_09.html (ì›”ë³„)
        year = target_date.year
        month = target_date.month
        day_num = target_date.day
        
        # NPB ì›”ë³„ ìº˜ë¦°ë” í˜ì´ì§€
        url = f"https://npb.jp/bis/{year}/calendar/index_{month:02d}.html"
        
        self.logger.info(f"ğŸ” Checking upcoming games: {target_date.strftime('%Y-%m-%d')}")
        
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            # Use raw bytes so BeautifulSoup can detect UTF-8 from meta
            soup = BeautifulSoup(response.content, 'html.parser')
            games = []
            
            # NPB ìº˜ë¦°ë” í…Œì´ë¸”ì—ì„œ íŠ¹ì • ë‚ ì§œ ì°¾ê¸°
            calendar_table = soup.find('table', class_='tetblmain')
            if not calendar_table:
                self.logger.warning(f"âš ï¸ Calendar table not found for {target_date.strftime('%Y-%m-%d')}")
                return []
            
            # ëª¨ë“  ë‚ ì§œ ì…€ ì°¾ê¸°
            date_cells = calendar_table.find_all('td', class_='stschedule')
            
            for cell in date_cells:
                # ë‚ ì§œ í™•ì¸
                date_div = cell.find('div', class_='teschedate')
                if not date_div:
                    continue
                    
                # ë‚ ì§œ í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ (ë§í¬ê°€ ìˆì„ ìˆ˜ ìˆìŒ)
                date_text = date_div.get_text(strip=True)
                try:
                    cell_day = int(date_text)
                except ValueError:
                    continue
                
                if cell_day == day_num:
                    self.logger.info(f"ğŸ“… Found date cell for day {day_num}")
                    
                    # í•´ë‹¹ ë‚ ì§œì˜ ê²½ê¸° ì •ë³´ ì¶”ì¶œ
                    game_divs = cell.find_all('div', class_='stvsteam')
                    self.logger.info(f"ğŸ“… Found {len(game_divs)} game div containers")
                    
                    for i, game_div in enumerate(game_divs):
                        game_texts = game_div.find_all('div')
                        self.logger.info(f"ğŸ“… Game div {i}: found {len(game_texts)} game text divs")
                        
                        for j, game_text_div in enumerate(game_texts):
                            game_text = game_text_div.get_text(strip=True)
                            self.logger.info(f"ğŸ“… Game text {j}: '{game_text}'")
                            
                            # ê²½ê¸° ì‹œê°„ì´ ìˆëŠ” ì˜ˆì • ê²½ê¸°ë§Œ ì²˜ë¦¬ (18:00, 14:00 ë“±)
                            if 'ï¼š' in game_text and ('-' in game_text or 'vs' in game_text):
                                self.logger.info(f"ğŸ“… Processing scheduled game: '{game_text}'")
                                try:
                                    # íŒ€ëª…ê³¼ ì‹œê°„ ë¶„ë¦¬ (ì˜ˆ: "å·¨ - ãƒ¤ã€€18ï¼š00")
                                    parts = game_text.split('ã€€')
                                    if len(parts) >= 2:
                                        team_part = parts[0].strip()
                                        time_part = parts[1].strip()
                                        self.logger.info(f"ğŸ“… Team part: '{team_part}', Time part: '{time_part}'")
                                        
                                        # íŒ€ëª… ì¶”ì¶œ
                                        if '-' in team_part:
                                            team_names = team_part.split('-')
                                        elif 'vs' in team_part:
                                            team_names = team_part.split('vs')
                                        else:
                                            self.logger.warning(f"âš ï¸ No separator found in team part: {team_part}")
                                            continue
                                            
                                        if len(team_names) >= 2:
                                            away_team_text = team_names[0].strip()
                                            home_team_text = team_names[1].strip()
                                            self.logger.info(f"ğŸ“… Away: '{away_team_text}', Home: '{home_team_text}'")
                                            
                                            away_team = self.get_team_info(away_team_text)
                                            home_team = self.get_team_info(home_team_text)
                                            
                                            if away_team and home_team:
                                                # ë¦¬ê·¸ íŒë‹¨: êµë¥˜ì „ í™•ì¸ í›„ ë¶„ë¥˜
                                                home_league = home_team['league']
                                                away_league = away_team['league']
                                                
                                                if home_league == away_league:
                                                    # ê°™ì€ ë¦¬ê·¸ ë‚´ ê²½ê¸°
                                                    league = home_league
                                                else:
                                                    # êµë¥˜ì „: í™ˆíŒ€ ë¦¬ê·¸ë¡œ ë¶„ë¥˜
                                                    league = home_league
                                                
                                                game = {
                                                    'date': target_date.strftime('%Y-%m-%d'),
                                                    'home_team_id': home_team['id'],
                                                    'home_team_name': home_team['name'],
                                                    'home_team_abbr': home_team['abbr'],
                                                    'away_team_id': away_team['id'],
                                                    'away_team_name': away_team['name'],
                                                    'away_team_abbr': away_team['abbr'],
                                                    'home_score': None,  # ì˜ˆì • ê²½ê¸°ëŠ” ì ìˆ˜ ì—†ìŒ
                                                    'away_score': None,
                                                    'league': league,
                                                    'status': 'scheduled',
                                                    'is_draw': False,
                                                    'winner': None,
                                                    'game_time': time_part
                                                }
                                                
                                                games.append(game)
                                                self.logger.info(f"ğŸ“… Scheduled: {away_team['abbr']} vs {home_team['abbr']} at {time_part}")
                                            else:
                                                self.logger.warning(f"âš ï¸ Team not found: away='{away_team_text}', home='{home_team_text}'")
                                                
                                except Exception as e:
                                    self.logger.warning(f"âš ï¸ Failed to parse game: {game_text} - {e}")
                                    continue
                    
                    break  # í•´ë‹¹ ë‚ ì§œë¥¼ ì°¾ì•˜ìœ¼ë¯€ë¡œ ë£¨í”„ ì¢…ë£Œ
            
            return games
            
        except Exception as e:
            self.logger.error(f"âŒ Failed to crawl upcoming games for {target_date.strftime('%Y-%m-%d')}: {e}")
            return []

def main():
    import sys
    
    crawler = SimpleCrawler()
    
    if len(sys.argv) > 1:
        if sys.argv[1] == '--full-season':
            # ì „ì²´ ì‹œì¦Œ í¬ë¡¤ë§ (3ì›” 28ì¼ë¶€í„°)
            games_count = crawler.crawl_full_season("2025-03-28")
            print(f"\nğŸ† Full season crawl completed: {games_count} games collected")
        elif sys.argv[1] == '--test':
            games_count = crawler.crawl_multiple_days(3)
            print(f"\nâœ… Test crawl completed: {games_count} games collected")
        elif sys.argv[1] == '--quick':
            games_count = crawler.crawl_multiple_days(1)
            print(f"\nâš¡ Quick crawl completed: {games_count} games collected")
        elif sys.argv[1] == '--upcoming':
            # ì˜ˆì • ê²½ê¸° í¬ë¡¤ë§ (ê¸°ë³¸ 30ì¼)
            upcoming_games = crawler.crawl_upcoming_games(30)
            games_count = len(upcoming_games)
            print(f"\nğŸ“… Upcoming games crawl completed: {games_count} games found")
        elif sys.argv[1] == '--date' and len(sys.argv) > 2:
            try:
                target_date = datetime.strptime(sys.argv[2], '%Y-%m-%d')
                games = crawler.crawl_date(target_date)
                if games:
                    crawler.save_games_to_txt(games)
                games_count = len(games)
                print(f"\nâœ… Crawl for date {sys.argv[2]} completed: {games_count} games collected")
            except ValueError:
                print("âŒ Invalid date format. Please use YYYY-MM-DD.")
                return 1
        else:
            try:
                days = int(sys.argv[1])
                games_count = crawler.crawl_multiple_days(days)
                print(f"\nâœ… Crawl completed: {games_count} games collected")
            except ValueError:
                print("âŒ Invalid argument. Available options:")
                print("  --full-season    : Crawl entire season")
                print("  --test           : Test crawl (3 days)")
                print("  --quick          : Quick crawl (1 day)")
                print("  --upcoming       : Upcoming games (30 days)")
                print("  <number>         : Crawl specific number of days")
                return 1
    else:
        # ê¸°ë³¸: 7ì¼
        games_count = crawler.crawl_multiple_days(7)
        print(f"\nâœ… Default crawl completed: {games_count} games collected")
    
    return 0 if games_count > 0 else 1

if __name__ == "__main__":
    exit(main())
