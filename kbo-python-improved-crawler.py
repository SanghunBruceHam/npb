#!/usr/bin/env python3
"""
KBO ë°ì´í„° í¬ë¡¤ë§ ì‹œìŠ¤í…œ - Python ê°œì„  ë²„ì „
ì‹¤ì œ Daum Sports í˜ì´ì§€ êµ¬ì¡°ì— ë§ê²Œ íŒŒì‹± ë¡œì§ ê°œì„ 
"""

import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import json
import time
import re
from datetime import datetime, timedelta
import pandas as pd
import os

class KBOImprovedCrawler:
    def __init__(self):
        self.base_urls = {
            'daum_schedule': 'https://sports.daum.net/schedule/kbo'
        }
        
        self.team_mapping = {
            'KIA': 'KIA', 'KT': 'KT', 'LG': 'LG', 'NC': 'NC', 'SSG': 'SSG',
            'ë‘ì‚°': 'ë‘ì‚°', 'ë¡¯ë°': 'ë¡¯ë°', 'ì‚¼ì„±': 'ì‚¼ì„±', 'í‚¤ì›€': 'í‚¤ì›€', 'í•œí™”': 'í•œí™”',
            'SK': 'SSG', 'ê¸°ì•„': 'KIA'
        }
        
        print("ğŸŸï¸ KBO Python ê°œì„  í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")

    def setup_selenium_driver(self, headless=False):
        """Selenium WebDriver ì„¤ì •"""
        print("ğŸš€ Selenium WebDriver ì„¤ì • ì¤‘...")
        
        chrome_options = Options()
        if headless:
            chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36')
        
        try:
            driver = webdriver.Chrome(options=chrome_options)
            print("âœ… Chrome WebDriver ì„¤ì • ì™„ë£Œ")
            return driver
        except Exception as e:
            print(f"âŒ WebDriver ì„¤ì • ì‹¤íŒ¨: {e}")
            return None

    def get_daum_sports_data(self, year=2025, month=7):
        """ë‹¤ìŒ ìŠ¤í¬ì¸ ì—ì„œ KBO ë°ì´í„° ê°€ì ¸ì˜¤ê¸° - ê°œì„ ëœ ë°©ë²•"""
        print(f"ğŸ“¡ ë‹¤ìŒ ìŠ¤í¬ì¸ ì—ì„œ {year}ë…„ {month}ì›” KBO ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
        
        driver = self.setup_selenium_driver(headless=False)
        if not driver:
            return []
        
        try:
            # ì›”ë³„ ìŠ¤ì¼€ì¤„ í˜ì´ì§€ë¡œ ì´ë™
            target_month = f"{year}{month:02d}"
            url = f"{self.base_urls['daum_schedule']}?date={target_month}"
            
            print(f"ğŸ”— ì ‘ì† URL: {url}")
            driver.get(url)
            
            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            time.sleep(5)
            
            # ìŠ¤í¬ë¦°ìƒ· ì €ì¥
            driver.save_screenshot('daum-improved-debug.png')
            print("ğŸ“¸ ë””ë²„ê·¸ ìŠ¤í¬ë¦°ìƒ· ì €ì¥: daum-improved-debug.png")
            
            # ì „ì²´ HTML ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
            html_source = driver.page_source
            soup = BeautifulSoup(html_source, 'html.parser')
            
            # ë°©ë²• 1: ê²½ê¸° ì¹´ë“œì—ì„œ ì§ì ‘ ì¶”ì¶œ
            games = self.extract_from_game_cards(soup)
            
            if not games:
                # ë°©ë²• 2: ìŠ¤ì¼€ì¤„ í…Œì´ë¸”ì—ì„œ ì¶”ì¶œ (ë°±ì—…)
                games = self.extract_from_schedule_table(soup)
            
            print(f"âœ… ì´ {len(games)}ê°œ ê²½ê¸° ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
            return games
            
        except Exception as e:
            print(f"âŒ ë‹¤ìŒ ìŠ¤í¬ì¸  í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []
        finally:
            time.sleep(3)  # í™•ì¸ì„ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
            driver.quit()

    def extract_from_game_cards(self, soup):
        """ê²½ê¸° ì¹´ë“œì—ì„œ ë°ì´í„° ì¶”ì¶œ (ë©”ì¸ ë°©ë²•)"""
        print("ğŸ¯ ê²½ê¸° ì¹´ë“œì—ì„œ ë°ì´í„° ì¶”ì¶œ ì‹œë„...")
        
        games = []
        
        # ê²½ê¸° ì¹´ë“œ ì°¾ê¸° - ë‹¤ì–‘í•œ ì„ íƒì ì‹œë„
        card_selectors = [
            '.match_info',
            '.game_info', 
            '.match_card',
            '[class*="match"]',
            '[class*="game"]'
        ]
        
        game_cards = []
        for selector in card_selectors:
            cards = soup.select(selector)
            if cards:
                print(f"ğŸ“‹ '{selector}' ì„ íƒìë¡œ {len(cards)}ê°œ ì¹´ë“œ ë°œê²¬")
                game_cards.extend(cards)
        
        # ì¤‘ë³µ ì œê±°
        unique_cards = []
        seen_texts = set()
        for card in game_cards:
            card_text = card.get_text(strip=True)[:100]  # ì²˜ìŒ 100ìë§Œ ë¹„êµ
            if card_text not in seen_texts:
                seen_texts.add(card_text)
                unique_cards.append(card)
        
        print(f"ğŸ“‹ ì¤‘ë³µ ì œê±° í›„ {len(unique_cards)}ê°œ ê³ ìœ  ì¹´ë“œ")
        
        # ê° ì¹´ë“œì—ì„œ ë°ì´í„° ì¶”ì¶œ
        for card_index, card in enumerate(unique_cards):
            try:
                game_data = self.parse_game_card(card, card_index)
                if game_data:
                    games.append(game_data)
            except Exception as e:
                print(f"âš ï¸ ì¹´ë“œ {card_index + 1} íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue
        
        return games

    def parse_game_card(self, card, card_index):
        """ê°œë³„ ê²½ê¸° ì¹´ë“œ íŒŒì‹±"""
        try:
            card_text = card.get_text(strip=True)
            
            # íŒ€ëª…ì´ í¬í•¨ëœ ì¹´ë“œì¸ì§€ í™•ì¸
            teams = ['KIA', 'KT', 'LG', 'NC', 'SSG', 'ë‘ì‚°', 'ë¡¯ë°', 'ì‚¼ì„±', 'í‚¤ì›€', 'í•œí™”']
            found_teams = [team for team in teams if team in card_text]
            
            if len(found_teams) < 2:
                return None
            
            print(f"\nğŸ¯ ì¹´ë“œ {card_index + 1} ë¶„ì„:")
            print(f"   í…ìŠ¤íŠ¸: {card_text[:100]}...")
            print(f"   ë°œê²¬ëœ íŒ€: {found_teams}")
            
            # ì ìˆ˜ íŒ¨í„´ ì°¾ê¸°
            score_patterns = [
                r'(\d+)\s*:\s*(\d+)',  # 3:2 í˜•íƒœ
                r'(\d+)\s*-\s*(\d+)',  # 3-2 í˜•íƒœ
                r'(\d+)\s+(\d+)'       # 3 2 í˜•íƒœ
            ]
            
            scores = []
            for pattern in score_patterns:
                matches = re.findall(pattern, card_text)
                for match in matches:
                    score1, score2 = int(match[0]), int(match[1])
                    if 0 <= score1 <= 30 and 0 <= score2 <= 30:  # ìœ íš¨í•œ ì ìˆ˜ ë²”ìœ„
                        scores.append((score1, score2))
            
            if not scores:
                print(f"   âŒ ì ìˆ˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return None
            
            # ë‚ ì§œ ì¶”ì¶œ
            date_patterns = [
                r'(\d{2})\.(\d{2})',    # 07.01 í˜•íƒœ
                r'(\d{1,2})ì›”\s*(\d{1,2})ì¼',  # 7ì›” 1ì¼ í˜•íƒœ
                r'2025[.-](\d{2})[.-](\d{2})'  # 2025-07-01 í˜•íƒœ
            ]
            
            game_date = None
            for pattern in date_patterns:
                match = re.search(pattern, card_text)
                if match:
                    month = match.group(1).zfill(2)
                    day = match.group(2).zfill(2)
                    game_date = f"2025-{month}-{day}"
                    break
            
            if not game_date:
                # ê¸°ë³¸ê°’ìœ¼ë¡œ í˜„ì¬ ë‚ ì§œ ì‚¬ìš©
                game_date = datetime.now().strftime('%Y-%m-%d')
            
            # ê²½ê¸° ë°ì´í„° ìƒì„±
            game_data = {
                'date': game_date,
                'away_team': self.normalize_team_name(found_teams[0]),
                'home_team': self.normalize_team_name(found_teams[1]),
                'away_score': scores[0][0],
                'home_score': scores[0][1],
                'source': f'card_{card_index + 1}',
                'raw_text': card_text[:200]
            }
            
            print(f"   âœ… ê²½ê¸° ì¶”ì¶œ: {game_data['away_team']} {game_data['away_score']}:{game_data['home_score']} {game_data['home_team']} ({game_data['date']})")
            return game_data
            
        except Exception as e:
            print(f"   âŒ ì¹´ë“œ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return None

    def extract_from_schedule_table(self, soup):
        """ìŠ¤ì¼€ì¤„ í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¶”ì¶œ (ë°±ì—… ë°©ë²•)"""
        print("ğŸ¯ ìŠ¤ì¼€ì¤„ í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¶”ì¶œ ì‹œë„...")
        
        games = []
        
        # í…Œì´ë¸” ì°¾ê¸°
        schedule_table = soup.find('tbody', id='scheduleList')
        if not schedule_table:
            print("âŒ ìŠ¤ì¼€ì¤„ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return []
        
        rows = schedule_table.find_all('tr')
        print(f"ğŸ“Š í…Œì´ë¸”ì—ì„œ {len(rows)}ê°œ í–‰ ë°œê²¬")
        
        current_date = None
        
        for row_index, row in enumerate(rows):
            cells = row.find_all('td')
            if len(cells) == 0:
                continue
            
            # ë‚ ì§œ ì…€ í™•ì¸
            date_cell = cells[0].get_text(strip=True)
            if re.match(r'\d{2}\.\d{2}', date_cell):
                month_day = date_cell.split('.')
                current_date = f"2025-{month_day[0]}-{month_day[1]}"
                continue
            
            if not current_date:
                continue
            
            # íŒ€ëª…ê³¼ ì ìˆ˜ ì¶”ì¶œ
            row_text = row.get_text(strip=True)
            teams = ['KIA', 'KT', 'LG', 'NC', 'SSG', 'ë‘ì‚°', 'ë¡¯ë°', 'ì‚¼ì„±', 'í‚¤ì›€', 'í•œí™”']
            found_teams = [team for team in teams if team in row_text]
            
            if len(found_teams) >= 2:
                # ì ìˆ˜ ì¶”ì¶œ
                scores = []
                for cell in cells:
                    cell_text = cell.get_text(strip=True)
                    if re.match(r'^\d+$', cell_text):
                        score = int(cell_text)
                        if 0 <= score <= 30:
                            scores.append(score)
                
                if len(scores) >= 2:
                    game_data = {
                        'date': current_date,
                        'away_team': self.normalize_team_name(found_teams[0]),
                        'home_team': self.normalize_team_name(found_teams[1]),
                        'away_score': scores[0],
                        'home_score': scores[1],
                        'source': f'table_row_{row_index + 1}',
                        'raw_text': row_text[:200]
                    }
                    
                    games.append(game_data)
                    print(f"âœ… í…Œì´ë¸”ì—ì„œ ê²½ê¸° ì¶”ì¶œ: {game_data['away_team']} {game_data['away_score']}:{game_data['home_score']} {game_data['home_team']} ({game_data['date']})")
        
        return games

    def normalize_team_name(self, team_name):
        """íŒ€ëª… ì •ê·œí™”"""
        if not team_name:
            return None
        
        cleaned = team_name.strip()
        return self.team_mapping.get(cleaned, cleaned)

    def convert_to_clean_format(self, games):
        """clean.txt í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        print("ğŸ”„ clean.txt í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ì¤‘...")
        
        # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
        date_groups = {}
        for game in games:
            date = game['date']
            if date not in date_groups:
                date_groups[date] = []
            
            # clean.txt í˜•ì‹: "ì›ì •íŒ€ ì ìˆ˜:ì ìˆ˜ í™ˆíŒ€(H)"
            clean_line = f"{game['away_team']} {game['away_score']}:{game['home_score']} {game['home_team']}(H)"
            date_groups[date].append(clean_line)
        
        # ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
        result = []
        for date in sorted(date_groups.keys()):
            result.append(date)
            for game_line in date_groups[date]:
                result.append(game_line)
            result.append('')  # ë¹ˆ ì¤„
        
        return '\n'.join(result).strip()

    def save_to_files(self, games, prefix='kbo-improved'):
        """ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # JSON íŒŒì¼ ì €ì¥
        json_filename = f"{prefix}-{timestamp}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(games, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ JSON íŒŒì¼ ì €ì¥: {json_filename}")
        
        # Clean.txt í˜•ì‹ ì €ì¥
        if games:
            clean_format = self.convert_to_clean_format(games)
            clean_filename = f"{prefix}-{timestamp}-clean.txt"
            with open(clean_filename, 'w', encoding='utf-8') as f:
                f.write(clean_format)
            print(f"ğŸ’¾ Clean.txt íŒŒì¼ ì €ì¥: {clean_filename}")
        
        return json_filename

    def run_crawling(self, year=2025, month=7):
        """í¬ë¡¤ë§ ì‹¤í–‰"""
        print(f"ğŸ¯ {year}ë…„ {month}ì›” KBO ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        
        # ë‹¤ìŒ ìŠ¤í¬ì¸ ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
        games = self.get_daum_sports_data(year, month)
        
        if games:
            # ì¤‘ë³µ ì œê±°
            unique_games = self.remove_duplicates(games)
            print(f"ğŸ”„ ì¤‘ë³µ ì œê±° í›„: {len(unique_games)}ê°œ ê²½ê¸°")
            
            # íŒŒì¼ë¡œ ì €ì¥
            filename = self.save_to_files(unique_games, f'kbo-{year}-{month:02d}')
            
            # ê²°ê³¼ ìš”ì•½
            print(f"\nğŸ“Š í¬ë¡¤ë§ ê²°ê³¼ ìš”ì•½:")
            print(f"- ì´ ê²½ê¸° ìˆ˜: {len(unique_games)}ê°œ")
            print(f"- ì €ì¥ íŒŒì¼: {filename}")
            
            # ë‚ ì§œë³„ ê²½ê¸° ìˆ˜ ì¶œë ¥
            date_counts = {}
            for game in unique_games:
                date = game['date']
                date_counts[date] = date_counts.get(date, 0) + 1
            
            print("\nğŸ“… ë‚ ì§œë³„ ê²½ê¸° ìˆ˜:")
            for date in sorted(date_counts.keys()):
                print(f"  {date}: {date_counts[date]}ê°œ ê²½ê¸°")
            
            # ìƒ˜í”Œ ê²½ê¸° ì¶œë ¥
            print("\nğŸŸï¸ ìƒ˜í”Œ ê²½ê¸°ë“¤:")
            for game in unique_games[:10]:
                print(f"  {game['date']}: {game['away_team']} {game['away_score']}:{game['home_score']} {game['home_team']}")
            
            return unique_games
        else:
            print("âŒ ìˆ˜ì§‘ëœ ê²½ê¸° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []

    def remove_duplicates(self, games):
        """ì¤‘ë³µ ê²½ê¸° ì œê±°"""
        unique_games = []
        seen_games = set()
        
        for game in games:
            # ê²Œì„ ì‹ë³„ì ìƒì„±
            game_key = f"{game['date']}-{game['away_team']}-{game['home_team']}-{game['away_score']}-{game['home_score']}"
            
            if game_key not in seen_games:
                seen_games.add(game_key)
                unique_games.append(game)
        
        return unique_games

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    crawler = KBOImprovedCrawler()
    
    print("=" * 60)
    print("ğŸŸï¸ KBO Python ê°œì„  í¬ë¡¤ë§ ì‹œìŠ¤í…œ")
    print("ğŸ“¡ ì‹¤ì œ í˜ì´ì§€ êµ¬ì¡°ì— ë§ê²Œ ìµœì í™”")
    print("=" * 60)
    
    # 2025ë…„ 7ì›” ë°ì´í„° ìˆ˜ì§‘
    results = crawler.run_crawling(2025, 7)
    
    print("\n" + "=" * 60)
    if results:
        print("âœ… KBO Python í¬ë¡¤ë§ ì„±ê³µ!")
        print(f"ğŸ“Š ì´ {len(results)}ê°œ ê²½ê¸° ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
    else:
        print("âŒ KBO Python í¬ë¡¤ë§ ì‹¤íŒ¨")
    print("=" * 60)

if __name__ == "__main__":
    main()